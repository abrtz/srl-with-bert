{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmZ_eppHYdEy"
   },
   "source": [
    "# Semantic role labeling with BERT\n",
    "\n",
    "In this notebook, you'll perform semantic role labeling with BERT, using the [English Universal Propbank 1.0 datasets](https://github.com/UniversalPropositions/UP-1.0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XJQ6KZ5YdE1"
   },
   "source": [
    "## Before you begin\n",
    "\n",
    "### Install libraries\n",
    "\n",
    "If you run this notebook in [Google colab](https://colab.research.google.com), make sure to install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jbVPypolapSm",
    "outputId": "15724fc3-54a5-4bb5-b183-ee594d92bda7"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    runs_in_colab =  True\n",
    "except ImportError:\n",
    "    runs_in_colab = False\n",
    "\n",
    "if runs_in_colab:\n",
    "    !pip install datasets\n",
    "    !pip install accelerate==0.21.0\n",
    "    !pip install transformers[torch]\n",
    "    !pip install accelerate -U\n",
    "\n",
    "    # Import the drive library to save your model, tokenizer and trainer to Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMFENJEVYdE3"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "vDwNetWfYdE3"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
    "from datasets import load_metric\n",
    "from datasets import Dataset\n",
    "from utils import read_data_as_sentence,map_labels_in_dataframe,tokenize_and_align_labels,get_label_mapping,get_labels_from_map,load_srl_model,load_dataset,compute_metrics,write_predictions_to_csv,compute_evaluation_metrics_from_csv, print_sentences\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from main_bert_srl import main, define_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AA7OmWe_YdE4"
   },
   "source": [
    "## Step 1: Preprocess data\n",
    "\n",
    "Unlike traditional token labeling methods, which assign labels to individual words in isolation, BERT performs sequence labeling. This means BERT assigns labels to individual tokens, while taking the full sentence context in consideration.\n",
    "\n",
    "The English Universal PropBank 1.0 dataset is structured in [CoNNL-U Plus format](https://universaldependencies.org/ext-format.html), in which lines represent individual tokens. So before you can train the model, you need to extract sentences and labels from the datasets, and preprocess the sentences by removing non-argument labels.\n",
    "\n",
    "To preprocess the datasets and save the resulting DataFrame to a file, call the `read_data_as_sentence()` function, including:\n",
    "\n",
    "| Parameter name     | Required | Parameter description |\n",
    "|--------------------|:--------------:|-------------|\n",
    "| *positional 1*  (string)                 | ✅️ | The filepath for the CoNNLU dataset. |\n",
    "| *positional 2*  (string)               | ✅ | The filepath to write the preprocessed DataFrame to. |\n",
    "| `mode` (enum)                          | Optional (defaults to **basic**) | The method of preprocessing, used for the advanced model. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "vyzGaxOIYdE5"
   },
   "outputs": [],
   "source": [
    "train_data = read_data_as_sentence('data/en_ewt-up-train.conllu', 'data/en_ewt-up-train.preprocessed.csv')\n",
    "dev_data = read_data_as_sentence('data/en_ewt-up-dev.conllu', 'data/en_ewt-up-dev.preprocessed.csv')\n",
    "test_data = read_data_as_sentence('data/en_ewt-up-test.conllu', 'data/en_ewt-up-test.preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61uzoDU4YdE6"
   },
   "source": [
    "The `read_data_as_sentence()` function returns DataFrames, where each row represents a sentence from the dataset passed to the function. Each sentence has been expanded based on its predicates, resulting in multiple copies of the same sentence, each focused on a different predicate.\n",
    "\n",
    "The DataFrame has two columns:\n",
    "\n",
    "- `input_form`: a list of strings, where each string represents a words in the sentence, followed by two special tokens:\n",
    "    1. A special token (`[SEP]`), which denotes the separation between the words of the sentence and the predicate form.\n",
    "    2. The predicate form, which corresponds to the `argument` values for the same row in the DataFrame.\n",
    "- `argument`: a list of strings, representing the arguments associated with each word in the sentence. The length of each list is equal to the number of words in the sentence, plus two additional elements, for the special token and predicate form. The arguments match the predicate appended to the `input_form` for the same row in the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWnvMr9OYdE6"
   },
   "source": [
    "### Explore the DataFrame\n",
    "\n",
    "Before you continue to tokenize the sentences and fine-tune the BERT model, it's time to get more familiar with our data.\n",
    "\n",
    "To explore the DataFrame, start by printing the head of the preprocessed DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OGHo8o63apSp",
    "outputId": "bb7ab2d4-e22d-4af9-c43a-4769a377b6ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3971 entries, 0 to 3970\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   input_form  3971 non-null   object\n",
      " 1   argument    3971 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 62.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(test_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtxwkQqYYdE7"
   },
   "source": [
    "The **Non-Null** count for both columns should match, indicating there are as many lists of `input_form` values as there are lists of `argument` values, namely one for each sentence.\n",
    "\n",
    "Next, print the words and their argument labels for the first 20 sentences of the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "onp3jN-7YdE7",
    "outputId": "e8f659f8-ebe3-4719-e72d-8e08d33706bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "form: What            argument: _\n",
      "form: if              argument: _\n",
      "form: Google          argument: ARG1\n",
      "form: Morphed         argument: _\n",
      "form: Into            argument: _\n",
      "form: GoogleOS        argument: ARG2\n",
      "form: ?               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: Morphed         argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: What            argument: _\n",
      "form: if              argument: _\n",
      "form: Google          argument: ARG0\n",
      "form: expanded        argument: _\n",
      "form: on              argument: _\n",
      "form: its             argument: _\n",
      "form: search          argument: _\n",
      "form: -               argument: _\n",
      "form: engine          argument: _\n",
      "form: (               argument: _\n",
      "form: and             argument: _\n",
      "form: now             argument: _\n",
      "form: e-mail          argument: _\n",
      "form: )               argument: _\n",
      "form: wares           argument: ARG1\n",
      "form: into            argument: _\n",
      "form: a               argument: _\n",
      "form: full            argument: _\n",
      "form: -               argument: _\n",
      "form: fledged         argument: _\n",
      "form: operating       argument: _\n",
      "form: system          argument: ARG4\n",
      "form: ?               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: expanded        argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: (               argument: _\n",
      "form: And             argument: _\n",
      "form: ,               argument: _\n",
      "form: by              argument: _\n",
      "form: the             argument: _\n",
      "form: way             argument: ARGM-DIS\n",
      "form: ,               argument: _\n",
      "form: is              argument: _\n",
      "form: anybody         argument: ARG1\n",
      "form: else            argument: _\n",
      "form: just            argument: _\n",
      "form: a               argument: _\n",
      "form: little          argument: _\n",
      "form: nostalgic       argument: ARG2\n",
      "form: for             argument: _\n",
      "form: the             argument: _\n",
      "form: days            argument: _\n",
      "form: when            argument: _\n",
      "form: that            argument: _\n",
      "form: was             argument: _\n",
      "form: a               argument: _\n",
      "form: good            argument: _\n",
      "form: thing           argument: _\n",
      "form: ?               argument: _\n",
      "form: )               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: is              argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: (               argument: _\n",
      "form: And             argument: _\n",
      "form: ,               argument: _\n",
      "form: by              argument: _\n",
      "form: the             argument: _\n",
      "form: way             argument: _\n",
      "form: ,               argument: _\n",
      "form: is              argument: _\n",
      "form: anybody         argument: _\n",
      "form: else            argument: _\n",
      "form: just            argument: _\n",
      "form: a               argument: _\n",
      "form: little          argument: _\n",
      "form: nostalgic       argument: _\n",
      "form: for             argument: _\n",
      "form: the             argument: _\n",
      "form: days            argument: ARGM-TMP\n",
      "form: when            argument: R-ARGM-TMP\n",
      "form: that            argument: ARG1\n",
      "form: was             argument: _\n",
      "form: a               argument: _\n",
      "form: good            argument: _\n",
      "form: thing           argument: ARG2\n",
      "form: ?               argument: _\n",
      "form: )               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: is              argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: This            argument: _\n",
      "form: BuzzMachine     argument: ARG2\n",
      "form: post            argument: _\n",
      "form: argues          argument: _\n",
      "form: that            argument: _\n",
      "form: Google          argument: _\n",
      "form: 's              argument: _\n",
      "form: rush            argument: _\n",
      "form: toward          argument: _\n",
      "form: ubiquity        argument: _\n",
      "form: might           argument: _\n",
      "form: backfire        argument: _\n",
      "form: --              argument: _\n",
      "form: which           argument: _\n",
      "form: we              argument: _\n",
      "form: 've             argument: _\n",
      "form: all             argument: _\n",
      "form: heard           argument: _\n",
      "form: before          argument: _\n",
      "form: ,               argument: _\n",
      "form: but             argument: _\n",
      "form: it              argument: _\n",
      "form: 's              argument: _\n",
      "form: particularly    argument: _\n",
      "form: well            argument: _\n",
      "form: -               argument: _\n",
      "form: put             argument: _\n",
      "form: in              argument: _\n",
      "form: this            argument: _\n",
      "form: post            argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: post            argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: This            argument: _\n",
      "form: BuzzMachine     argument: _\n",
      "form: post            argument: ARG0\n",
      "form: argues          argument: _\n",
      "form: that            argument: _\n",
      "form: Google          argument: _\n",
      "form: 's              argument: _\n",
      "form: rush            argument: _\n",
      "form: toward          argument: _\n",
      "form: ubiquity        argument: _\n",
      "form: might           argument: _\n",
      "form: backfire        argument: ARG1\n",
      "form: --              argument: _\n",
      "form: which           argument: _\n",
      "form: we              argument: _\n",
      "form: 've             argument: _\n",
      "form: all             argument: _\n",
      "form: heard           argument: _\n",
      "form: before          argument: _\n",
      "form: ,               argument: _\n",
      "form: but             argument: _\n",
      "form: it              argument: _\n",
      "form: 's              argument: _\n",
      "form: particularly    argument: _\n",
      "form: well            argument: _\n",
      "form: -               argument: _\n",
      "form: put             argument: _\n",
      "form: in              argument: _\n",
      "form: this            argument: _\n",
      "form: post            argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: argues          argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: This            argument: _\n",
      "form: BuzzMachine     argument: _\n",
      "form: post            argument: _\n",
      "form: argues          argument: _\n",
      "form: that            argument: _\n",
      "form: Google          argument: ARG1\n",
      "form: 's              argument: _\n",
      "form: rush            argument: _\n",
      "form: toward          argument: _\n",
      "form: ubiquity        argument: ARG2\n",
      "form: might           argument: _\n",
      "form: backfire        argument: _\n",
      "form: --              argument: _\n",
      "form: which           argument: _\n",
      "form: we              argument: _\n",
      "form: 've             argument: _\n",
      "form: all             argument: _\n",
      "form: heard           argument: _\n",
      "form: before          argument: _\n",
      "form: ,               argument: _\n",
      "form: but             argument: _\n",
      "form: it              argument: _\n",
      "form: 's              argument: _\n",
      "form: particularly    argument: _\n",
      "form: well            argument: _\n",
      "form: -               argument: _\n",
      "form: put             argument: _\n",
      "form: in              argument: _\n",
      "form: this            argument: _\n",
      "form: post            argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: rush            argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: This            argument: _\n",
      "form: BuzzMachine     argument: _\n",
      "form: post            argument: _\n",
      "form: argues          argument: _\n",
      "form: that            argument: _\n",
      "form: Google          argument: _\n",
      "form: 's              argument: _\n",
      "form: rush            argument: ARG1\n",
      "form: toward          argument: _\n",
      "form: ubiquity        argument: _\n",
      "form: might           argument: ARGM-MOD\n",
      "form: backfire        argument: _\n",
      "form: --              argument: _\n",
      "form: which           argument: _\n",
      "form: we              argument: _\n",
      "form: 've             argument: _\n",
      "form: all             argument: _\n",
      "form: heard           argument: ARGM-ADV\n",
      "form: before          argument: _\n",
      "form: ,               argument: _\n",
      "form: but             argument: _\n",
      "form: it              argument: _\n",
      "form: 's              argument: _\n",
      "form: particularly    argument: _\n",
      "form: well            argument: _\n",
      "form: -               argument: _\n",
      "form: put             argument: _\n",
      "form: in              argument: _\n",
      "form: this            argument: _\n",
      "form: post            argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: backfire        argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: This            argument: _\n",
      "form: BuzzMachine     argument: _\n",
      "form: post            argument: _\n",
      "form: argues          argument: _\n",
      "form: that            argument: _\n",
      "form: Google          argument: _\n",
      "form: 's              argument: _\n",
      "form: rush            argument: _\n",
      "form: toward          argument: _\n",
      "form: ubiquity        argument: _\n",
      "form: might           argument: _\n",
      "form: backfire        argument: _\n",
      "form: --              argument: _\n",
      "form: which           argument: ARG1\n",
      "form: we              argument: ARG0\n",
      "form: 've             argument: _\n",
      "form: all             argument: ARGM-ADV\n",
      "form: heard           argument: _\n",
      "form: before          argument: ARGM-TMP\n",
      "form: ,               argument: _\n",
      "form: but             argument: _\n",
      "form: it              argument: _\n",
      "form: 's              argument: _\n",
      "form: particularly    argument: _\n",
      "form: well            argument: _\n",
      "form: -               argument: _\n",
      "form: put             argument: _\n",
      "form: in              argument: _\n",
      "form: this            argument: _\n",
      "form: post            argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: heard           argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: This            argument: _\n",
      "form: BuzzMachine     argument: _\n",
      "form: post            argument: _\n",
      "form: argues          argument: _\n",
      "form: that            argument: _\n",
      "form: Google          argument: _\n",
      "form: 's              argument: _\n",
      "form: rush            argument: _\n",
      "form: toward          argument: _\n",
      "form: ubiquity        argument: _\n",
      "form: might           argument: _\n",
      "form: backfire        argument: _\n",
      "form: --              argument: _\n",
      "form: which           argument: _\n",
      "form: we              argument: _\n",
      "form: 've             argument: _\n",
      "form: all             argument: _\n",
      "form: heard           argument: _\n",
      "form: before          argument: _\n",
      "form: ,               argument: _\n",
      "form: but             argument: _\n",
      "form: it              argument: ARG1\n",
      "form: 's              argument: _\n",
      "form: particularly    argument: ARGM-ADV\n",
      "form: well            argument: _\n",
      "form: -               argument: _\n",
      "form: put             argument: ARG2\n",
      "form: in              argument: _\n",
      "form: this            argument: _\n",
      "form: post            argument: ARGM-LOC\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: 's              argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: Google          argument: ARG1\n",
      "form: is              argument: _\n",
      "form: a               argument: _\n",
      "form: nice            argument: _\n",
      "form: search          argument: _\n",
      "form: engine          argument: ARG2\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: is              argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: Does            argument: _\n",
      "form: anybody         argument: ARG0\n",
      "form: use             argument: _\n",
      "form: it              argument: ARG1\n",
      "form: for             argument: _\n",
      "form: anything        argument: ARG2\n",
      "form: else            argument: _\n",
      "form: ?               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: use             argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: They            argument: ARG0\n",
      "form: own             argument: _\n",
      "form: blogger         argument: ARG1\n",
      "form: ,               argument: _\n",
      "form: of              argument: ARGM-ADV\n",
      "form: course          argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: own             argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: Is              argument: _\n",
      "form: that            argument: ARG1\n",
      "form: a               argument: _\n",
      "form: money           argument: _\n",
      "form: maker           argument: ARG2\n",
      "form: ?               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: Is              argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: I               argument: ARG1\n",
      "form: 'm              argument: _\n",
      "form: staying         argument: _\n",
      "form: away            argument: ARG3\n",
      "form: from            argument: _\n",
      "form: the             argument: _\n",
      "form: stock           argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: staying         argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: I               argument: ARG0\n",
      "form: doubt           argument: _\n",
      "form: the             argument: _\n",
      "form: very            argument: _\n",
      "form: few             argument: _\n",
      "form: who             argument: _\n",
      "form: actually        argument: _\n",
      "form: read            argument: _\n",
      "form: my              argument: _\n",
      "form: blog            argument: _\n",
      "form: have            argument: _\n",
      "form: not             argument: _\n",
      "form: come            argument: ARG1\n",
      "form: across          argument: _\n",
      "form: this            argument: _\n",
      "form: yet             argument: _\n",
      "form: ,               argument: _\n",
      "form: but             argument: _\n",
      "form: I               argument: _\n",
      "form: figured         argument: _\n",
      "form: I               argument: _\n",
      "form: would           argument: _\n",
      "form: put             argument: _\n",
      "form: it              argument: _\n",
      "form: out             argument: _\n",
      "form: there           argument: _\n",
      "form: anyways         argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: doubt           argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: I               argument: _\n",
      "form: doubt           argument: _\n",
      "form: the             argument: _\n",
      "form: very            argument: _\n",
      "form: few             argument: ARG0\n",
      "form: who             argument: R-ARG0\n",
      "form: actually        argument: ARGM-ADV\n",
      "form: read            argument: _\n",
      "form: my              argument: _\n",
      "form: blog            argument: ARG1\n",
      "form: have            argument: _\n",
      "form: not             argument: _\n",
      "form: come            argument: _\n",
      "form: across          argument: _\n",
      "form: this            argument: _\n",
      "form: yet             argument: _\n",
      "form: ,               argument: _\n",
      "form: but             argument: _\n",
      "form: I               argument: _\n",
      "form: figured         argument: _\n",
      "form: I               argument: _\n",
      "form: would           argument: _\n",
      "form: put             argument: _\n",
      "form: it              argument: _\n",
      "form: out             argument: _\n",
      "form: there           argument: _\n",
      "form: anyways         argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: read            argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: I               argument: _\n",
      "form: doubt           argument: _\n",
      "form: the             argument: _\n",
      "form: very            argument: _\n",
      "form: few             argument: ARG0\n",
      "form: who             argument: _\n",
      "form: actually        argument: _\n",
      "form: read            argument: _\n",
      "form: my              argument: _\n",
      "form: blog            argument: _\n",
      "form: have            argument: _\n",
      "form: not             argument: ARGM-NEG\n",
      "form: come            argument: _\n",
      "form: across          argument: _\n",
      "form: this            argument: ARG1\n",
      "form: yet             argument: ARGM-TMP\n",
      "form: ,               argument: _\n",
      "form: but             argument: _\n",
      "form: I               argument: _\n",
      "form: figured         argument: _\n",
      "form: I               argument: _\n",
      "form: would           argument: _\n",
      "form: put             argument: _\n",
      "form: it              argument: _\n",
      "form: out             argument: _\n",
      "form: there           argument: _\n",
      "form: anyways         argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: come            argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: I               argument: _\n",
      "form: doubt           argument: _\n",
      "form: the             argument: _\n",
      "form: very            argument: _\n",
      "form: few             argument: _\n",
      "form: who             argument: _\n",
      "form: actually        argument: _\n",
      "form: read            argument: _\n",
      "form: my              argument: _\n",
      "form: blog            argument: _\n",
      "form: have            argument: _\n",
      "form: not             argument: _\n",
      "form: come            argument: _\n",
      "form: across          argument: _\n",
      "form: this            argument: _\n",
      "form: yet             argument: _\n",
      "form: ,               argument: _\n",
      "form: but             argument: _\n",
      "form: I               argument: ARG0\n",
      "form: figured         argument: _\n",
      "form: I               argument: _\n",
      "form: would           argument: _\n",
      "form: put             argument: ARG1\n",
      "form: it              argument: _\n",
      "form: out             argument: _\n",
      "form: there           argument: _\n",
      "form: anyways         argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: figured         argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: I               argument: _\n",
      "form: doubt           argument: _\n",
      "form: the             argument: _\n",
      "form: very            argument: _\n",
      "form: few             argument: _\n",
      "form: who             argument: _\n",
      "form: actually        argument: _\n",
      "form: read            argument: _\n",
      "form: my              argument: _\n",
      "form: blog            argument: _\n",
      "form: have            argument: _\n",
      "form: not             argument: _\n",
      "form: come            argument: _\n",
      "form: across          argument: _\n",
      "form: this            argument: _\n",
      "form: yet             argument: _\n",
      "form: ,               argument: _\n",
      "form: but             argument: _\n",
      "form: I               argument: _\n",
      "form: figured         argument: _\n",
      "form: I               argument: ARG0\n",
      "form: would           argument: ARGM-MOD\n",
      "form: put             argument: _\n",
      "form: it              argument: ARG1\n",
      "form: out             argument: _\n",
      "form: there           argument: ARG2\n",
      "form: anyways         argument: ARGM-ADV\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: put             argument: None\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_sentences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWiq1HplapSq"
   },
   "source": [
    "As you can see, the sequence of word forms runs parallel to the sequence of argument labels. This means that for every index of `input_form`, the same index of `argument` gives its argument label.\n",
    "\n",
    "Argument labels are:\n",
    "- **'_'** for tokens that are not an argument (in the current predicate sense of the sentence).\n",
    "- The token's respective Propbank label for tokens that are an argument, e.g. **ARG1**\n",
    "- **None** for the special separator token (`[SEP]`) and the predicate token that follows the separator.\n",
    "\n",
    "For example, in the the first sentence of the test data printed above (\"What if Google Morphed Into GoogleOS?\"), the predicate 'Morphed' evokes [the frame `morph.01`](https://propbank.github.io/v3.4.0/frames/morph.html#morph.01). The frame's arguments are:\n",
    "\n",
    "- `ARG0-PAG`: causer of transformation\n",
    "- `ARG1-PPT`: thing changing\n",
    "- `ARG2-PRD`: end state\n",
    "- `ARG3-VSP`: start state\n",
    "\n",
    "In this example, the `ARG1` label is assigned to 'Google', and the `ARG2` label is assigned to 'GoogleOS', which indicates 'Google' is the thing that is changing and 'GoogleOS' is its end state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSXRRKutYdE7"
   },
   "source": [
    "## Step 2: Initialize a tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5g8f-8dYdE8"
   },
   "source": [
    "Now that you have extracted sentences and labels from the datasets, you need to prepare the sentences for the BERT model by tokenizing them.\n",
    "\n",
    "Use HuggingFace's [`AutoTokenizer`](https://huggingface.co/docs/transformers/v4.38.2/en/model_doc/auto#transformers.AutoTokenizer) to construct a DistilBERT tokenizer, which is based on the WordPiece algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJxQoz_GYdE8",
    "outputId": "25116b59-2c07-4441-bcae-60ccac880356"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /Users/kris/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.16.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt from cache at /Users/kris/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer.json from cache at /Users/kris/.cache/huggingface/transformers/75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json from cache at /Users/kris/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /Users/kris/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.16.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the model ID to use\n",
    "model_id = \"distilbert-base-uncased\"\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Check the assertion that the tokenizer is an instance of transformers.PreTrainedTokenizerFast\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vi0vG2xMYdE8"
   },
   "source": [
    "To test the `tokenizer()`, tokenize the first sentence of the test data, including:\n",
    "\n",
    "- `add_special_tokens` set to **True** to add a `[CLS]` token to the start of every sentence.\n",
    "- `is_split_into_words` set to **True** because the sentence is already split into words (based on the Universal Propbank 1.0 dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Wg7_MEckUoi",
    "outputId": "80d49153-8131-4113-d7f0-7cec86b1a96b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     [CLS] 101\n",
      "      what 2054\n",
      "        if 2065\n",
      "    google 8224\n",
      "       mor 22822\n",
      "      ##ph 8458\n",
      "      ##ed 2098\n",
      "      into 2046\n",
      "    google 8224\n",
      "      ##os 2891\n",
      "         ? 1029\n",
      "     [SEP] 102\n",
      "       mor 22822\n",
      "      ##ph 8458\n",
      "      ##ed 2098\n",
      "     [SEP] 102\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the first example in the test data\n",
    "example = test_data['input_form'][0]\n",
    "tokenized_input = tokenizer(example,add_special_tokens=True, is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "\n",
    "# Print the example tokens and their corresponding IDs\n",
    "for token, id in zip(tokens, tokenized_input[\"input_ids\"]):\n",
    "    print(f\"{token:>10} {id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOFsSEewapSr"
   },
   "source": [
    "You've successfully tokenized the sample sentence, splitting words up into subword tokens and fetching their token IDs from DistilBERT's vocabulary.\n",
    "\n",
    "> Note: notice how the special tokens `[CLS]` and `[SEP]` are tokenized as **101** and **102**. These numbers are meaningful to BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lERE6j_HYdE-"
   },
   "source": [
    "## Step 3: Prepare the input for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8BO8OyoYdE-"
   },
   "source": [
    "Before training the model, map the labels in the datasets to numerical values. This ensures consistency and facilitates the training process.\n",
    "\n",
    "To get the label mapping, call `get_label_mapping()`, including:\n",
    "\n",
    "| Parameter name     | Required | Parameter description |\n",
    "|--------------------|:--------------:|-------------|\n",
    "| *positional 1* (DataFrame)          | ✅️ | The training dataset for which to extract the label mapping. |\n",
    "| *positional 2* (DataFrame)          | ✅ | The test dataset for which to extract the label mapping.|\n",
    "| *positional 3* (DataFrame)          | ✅ | The dev dataset for which to extract the label mapping. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "kangOKNiYdE-"
   },
   "outputs": [],
   "source": [
    "label_map = get_label_mapping(train_data, test_data, dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dfd-JBwwapSs"
   },
   "source": [
    "The `get_label_mapping()` function returns an alphabetically-ordered dictionary mapping:\n",
    "- **_** to **0**.\n",
    "- String labels to integers, e.g. **ARG0** to **1**.\n",
    "- **None** to **None**, to preserve the labels for special tokens and predicates. (You will replace **None** with **-100** later to mask these tokens from being labeled.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Id6U73tRYdE_",
    "outputId": "81ca2027-3c86-4404-e22b-909f236144c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_': 0, 'ARG0': 1, 'ARG1': 2, 'ARG1-DSP': 3, 'ARG2': 4, 'ARG3': 5, 'ARG4': 6, 'ARG5': 7, 'ARGA': 8, 'ARGM-ADJ': 9, 'ARGM-ADV': 10, 'ARGM-CAU': 11, 'ARGM-COM': 12, 'ARGM-CXN': 13, 'ARGM-DIR': 14, 'ARGM-DIS': 15, 'ARGM-EXT': 16, 'ARGM-GOL': 17, 'ARGM-LOC': 18, 'ARGM-LVB': 19, 'ARGM-MNR': 20, 'ARGM-MOD': 21, 'ARGM-NEG': 22, 'ARGM-PRD': 23, 'ARGM-PRP': 24, 'ARGM-PRR': 25, 'ARGM-REC': 26, 'ARGM-TMP': 27, 'C-ARG0': 28, 'C-ARG1': 29, 'C-ARG1-DSP': 30, 'C-ARG2': 31, 'C-ARG3': 32, 'C-ARG4': 33, 'C-ARGM-ADV': 34, 'C-ARGM-COM': 35, 'C-ARGM-CXN': 36, 'C-ARGM-DIR': 37, 'C-ARGM-EXT': 38, 'C-ARGM-GOL': 39, 'C-ARGM-LOC': 40, 'C-ARGM-MNR': 41, 'C-ARGM-PRP': 42, 'C-ARGM-PRR': 43, 'C-ARGM-TMP': 44, 'R-ARG0': 45, 'R-ARG1': 46, 'R-ARG2': 47, 'R-ARG3': 48, 'R-ARG4': 49, 'R-ARGM-ADJ': 50, 'R-ARGM-ADV': 51, 'R-ARGM-CAU': 52, 'R-ARGM-COM': 53, 'R-ARGM-DIR': 54, 'R-ARGM-GOL': 55, 'R-ARGM-LOC': 56, 'R-ARGM-MNR': 57, 'R-ARGM-TMP': 58, None: None}\n"
     ]
    }
   ],
   "source": [
    "print(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WiyFPfnuYdFA"
   },
   "source": [
    "\n",
    "Next, apply the label mapping to the datasets, adding the column `mapped_labels` to the DataFrames. This column contains arrays of integers representing the labels, based on the label mapping.\n",
    "\n",
    "To apply the label mapping, call `map_labels_in_dataframe()`, including:\n",
    "\n",
    "| Parameter name     | Required | Parameter description |\n",
    "|--------------------|:--------------:|-------------|\n",
    "| *positional 1*                   | ✅️ | The DataFrame for which to convert the argument labels. |\n",
    "| *positional 2*                 | ✅ | The label mapping, created with `get_label_mapping()`. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "N1Cy6U0nYdFB"
   },
   "outputs": [],
   "source": [
    "train_data = map_labels_in_dataframe(train_data, label_map)\n",
    "dev_data = map_labels_in_dataframe(dev_data, label_map)\n",
    "test_data = map_labels_in_dataframe(test_data, label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1MzLjuoYdFB"
   },
   "source": [
    "As you can see, for each row in the DataFrame, the values in `mapped_labels` and `arguments` correspond to the mapping in `label_map`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "NrsuWwugYdFB",
    "outputId": "99ce8722-5d7b-48a9-ba26-78b853c77ea3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_form</th>\n",
       "      <th>argument</th>\n",
       "      <th>mapped_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[What, if, Google, Morphed, Into, GoogleOS, ?,...</td>\n",
       "      <td>[_, _, ARG1, _, _, ARG2, _, None, None]</td>\n",
       "      <td>[0, 0, 2, 0, 0, 4, 0, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[What, if, Google, expanded, on, its, search, ...</td>\n",
       "      <td>[_, _, ARG0, _, _, _, _, _, _, _, _, _, _, _, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(, And, ,, by, the, way, ,, is, anybody, else...</td>\n",
       "      <td>[_, _, _, _, _, ARGM-DIS, _, _, ARG1, _, _, _,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 15, 0, 0, 2, 0, 0, 0, 0, 4, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(, And, ,, by, the, way, ,, is, anybody, else...</td>\n",
       "      <td>[_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[This, BuzzMachine, post, argues, that, Google...</td>\n",
       "      <td>[_, ARG2, _, _, _, _, _, _, _, _, _, _, _, _, ...</td>\n",
       "      <td>[0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_form  \\\n",
       "0  [What, if, Google, Morphed, Into, GoogleOS, ?,...   \n",
       "1  [What, if, Google, expanded, on, its, search, ...   \n",
       "2  [(, And, ,, by, the, way, ,, is, anybody, else...   \n",
       "3  [(, And, ,, by, the, way, ,, is, anybody, else...   \n",
       "4  [This, BuzzMachine, post, argues, that, Google...   \n",
       "\n",
       "                                            argument  \\\n",
       "0            [_, _, ARG1, _, _, ARG2, _, None, None]   \n",
       "1  [_, _, ARG0, _, _, _, _, _, _, _, _, _, _, _, ...   \n",
       "2  [_, _, _, _, _, ARGM-DIS, _, _, ARG1, _, _, _,...   \n",
       "3  [_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, ...   \n",
       "4  [_, ARG2, _, _, _, _, _, _, _, _, _, _, _, _, ...   \n",
       "\n",
       "                                       mapped_labels  \n",
       "0                  [0, 0, 2, 0, 0, 4, 0, None, None]  \n",
       "1  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, ...  \n",
       "2  [0, 0, 0, 0, 0, 15, 0, 0, 2, 0, 0, 0, 0, 4, 0,...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78d8pDrEYdFB"
   },
   "source": [
    "Now that you have initialized and tested the `tokenizer()` and added mapped labels to the DataFrames, it's time to tokenize (and pad) all sentences.\n",
    "\n",
    "Since WordPiece tokenization potentially breaks words up into subword tokens, the tokens and their labels have to be re-aligned. The `tokenize_and_align_labels()` function you'll call for this iterates over each token and determines the appropriate label based on the provided dataset.\n",
    "\n",
    "Special tokens are assigned a label of **-100** to indicate they should be ignored in the loss function. Labels for the first token of each word are set accordingly, while labels for subsequent tokens within the same word are determined based on the `label_all_tokens` flag.\n",
    "\n",
    "To tokenize the sentences and align the labels, call `tokenize_and_align_labels()`, including:\n",
    "\n",
    "| Parameter name     | Required | Parameter description |\n",
    "|--------------------|:--------------:|-------------|\n",
    "| *positional 1* (`transformers AutoTokenizer`) | ✅️ | The `tokenizer()` for the pre-trained model. |\n",
    "| *positional 2* (DataFrame) | ✅ | The preprocessed datasets |\n",
    "| `label_all_tokens` (boolean)     | Optional (defaults to **True**) | Whether all tokens should receive their own label, accounting for words split into subtokens |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "OHRNa98wYdFB"
   },
   "outputs": [],
   "source": [
    "tokenized_test = tokenize_and_align_labels(tokenizer, test_data, label_all_tokens=True)\n",
    "tokenized_train = tokenize_and_align_labels(tokenizer, train_data, label_all_tokens=True)\n",
    "tokenized_dev = tokenize_and_align_labels(tokenizer, dev_data, label_all_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9WeeG8YYdFB"
   },
   "source": [
    "Now that you have tokenized all three datasets, let's examine the result.\n",
    "\n",
    "The `tokenized_` datasets are of the type `transformers.tokenization_utils_base.BatchEncoding` and have three attributes per row:\n",
    "\n",
    "1. `input_ids`: an array of token IDs for the tokenized sentence. Starts with the token ID for the `[CLS]` token, followed by the tokenized sentence, the `[SEP]` token, the predicate, and a final `[SEP]` token.\n",
    "2. `attention_mask`: an array representing the attention mask for the sentence.\n",
    "3. `labels`: an array with numerical labels, aligned with the tokens.\n",
    "\n",
    "> Note: all three arrays are padded so that every sample per dataset is of equal length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e23nB-4dYdFB",
    "outputId": "798f512e-de56-4a9a-d144-4445a7899bed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
      "['[CLS]', 'what', 'if', 'google', 'mor', '##ph', '##ed', 'into', 'google', '##os', '?', '[SEP]', 'mor', '##ph', '##ed', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "input_ids: tensor([  101,  2054,  2065,  8224, 22822,  8458,  2098,  2046,  8224,  2891,\n",
      "         1029,   102, 22822,  8458,  2098,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0])\n",
      "attention_mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "labels: [-100, 0, 0, 2, 0, 0, 0, 0, 4, 4, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"
     ]
    }
   ],
   "source": [
    "print(type(tokenized_test))\n",
    "print(tokenized_test.keys())\n",
    "print(tokenizer.convert_ids_to_tokens(tokenized_test[\"input_ids\"][0]))\n",
    "for key in tokenized_test.keys():\n",
    "    print(f\"{key}: {tokenized_test[key][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j31tpMcxYdFB"
   },
   "source": [
    "To confirm that you have padded all sentences in the `tokenized_test` dataset to be of equal length, let's check the length of all three arrays for the first 10 sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vp6JKWx6YdFC",
    "outputId": "1a13d704-e7cf-418d-dae9-4faa4eeaecc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 0: input_ids: 97 \tlabels: 97 \tattention_mask: 97\n",
      "sentence 1: input_ids: 97 \tlabels: 97 \tattention_mask: 97\n",
      "sentence 2: input_ids: 97 \tlabels: 97 \tattention_mask: 97\n",
      "sentence 3: input_ids: 97 \tlabels: 97 \tattention_mask: 97\n",
      "sentence 4: input_ids: 97 \tlabels: 97 \tattention_mask: 97\n",
      "sentence 5: input_ids: 97 \tlabels: 97 \tattention_mask: 97\n",
      "sentence 6: input_ids: 97 \tlabels: 97 \tattention_mask: 97\n",
      "sentence 7: input_ids: 97 \tlabels: 97 \tattention_mask: 97\n",
      "sentence 8: input_ids: 97 \tlabels: 97 \tattention_mask: 97\n",
      "sentence 9: input_ids: 97 \tlabels: 97 \tattention_mask: 97\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"sentence {i}:\", \"input_ids:\", len(tokenized_test[\"input_ids\"][i]), \"\\tlabels:\", len(tokenized_test[\"labels\"][i]), \"\\tattention_mask:\", len(tokenized_test[\"attention_mask\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uui9puOfYdFC"
   },
   "source": [
    "Now that you have tokenized and padded the sentences, and aligned the labels with the tokens, you're ready to transform the tokenized datasets into Hugging Face's [`datasets.arrow_dataset.Dataset`](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset).\n",
    "\n",
    "To transform the tokenized datasets into `Dataset` objects, call the `load_dataset()` function, which calls the [`Dataset.from_dict()` method](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.from_dict), including:\n",
    "\n",
    "| Parameter name     | Required | Parameter description |\n",
    "|--------------------|:--------------:|-------------|\n",
    "| *positional 1* (`transformers.tokenization_utils_base.BatchEncoding`) | ✅️ | The tokenized dataset. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "kBKxTmz3YdFC"
   },
   "outputs": [],
   "source": [
    "dataset_train = load_dataset(tokenized_train)\n",
    "dataset_dev = load_dataset(tokenized_dev)\n",
    "dataset_test = load_dataset(tokenized_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZQRfvuPapSv"
   },
   "source": [
    "Let's print the type of the resulting dataset, to confirm the transformation into `datasets.arrow_dataset.Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VX4HNMdEapSv",
    "outputId": "ec4ace68-d432-4b01-a64d-5164390623b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-Pl5GvcYdFC"
   },
   "source": [
    "## Step 4: Fine-tune the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5yTu8JzYdFC"
   },
   "source": [
    "Finally, the sentences have been transformed from CoNNL-U Plus format to Hugging Face `Dataset` objects: it's time to fine-tune BERT!\n",
    "\n",
    "Fine-tuning a BERT model on the full dataset can be a very computationally challenging task. To speed up the process, create subsets of the three datasets with 1000 samples per dataset, selected randomly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "SLNvuvOvYdFD"
   },
   "outputs": [],
   "source": [
    "small_train_dataset = dataset_train.shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = dataset_dev.shuffle(seed=42).select(range(1000))\n",
    "small_test_dataset = dataset_test.shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BzGFWMKYdFE"
   },
   "source": [
    "To map the numerical labels back to their string representations, you need to convert the `label_map` dictionary to a list of labels (as strings).\n",
    "\n",
    "To convert the `label_map` to a list of labels (as strings), call the `get_labels_from_map()` function, including:\n",
    "\n",
    "| Parameter name     | Required | Parameter description |\n",
    "|--------------------|:--------------:|-------------|\n",
    "| *positional 1* (dictionary) | ✅️ | The dictionary mapping labels as strings to their numerical represenation. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "qGc0sBr1YdFE"
   },
   "outputs": [],
   "source": [
    "label_list = get_labels_from_map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCsgWLXQYdFE"
   },
   "source": [
    "Next, load the pretrained DistilBERT model using the [`AutoModelForTokenClassification.from_pretrained()` method](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained) from the `transformers` library, together with the model name (**distilbert-base-uncased**), and the [`TrainingArguments`](https://huggingface.co/docs/transformers/v4.38.2/en/main_classes/trainer#transformers.TrainingArguments) neccesary for training.\n",
    "\n",
    "To get the model, model name and `TrainingArguments`, call the `load_srl_model()` function, including:\n",
    "\n",
    "| Parameter name     | Required | Parameter description |\n",
    "|--------------------|:--------------:|-------------|\n",
    "| *positional 1* (string) | ✅️ | The model identifier.  |\n",
    "| *positional 2* (list of strings) | ✅️ | The tokenized dataset. |\n",
    "| `batch_size` (integer) | Optional (defaults to **16**) | The [batch size for training](https://huggingface.co/docs/transformers/main/en/perf_train_gpu_one#methods-and-tools-for-efficient-training-on-a-single-gpu) and [inference](https://huggingface.co/docs/setfit/main/en/how_to/batch_sizes). |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t8OACqyhYdFF",
    "outputId": "839baca7-72bb-49ab-81f5-6a80b8b46719"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /Users/kris/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.16.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /Users/kris/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "model, args = load_srl_model(model_id, label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFTYKnm1YdFF"
   },
   "source": [
    "Now that you have a DistilBERT model, it's time for fine-tuning the model for the task of semantic role labeling (SRL).\n",
    "\n",
    "To fine-tune your model, instantiate a [`Trainer` object](https://huggingface.co/docs/transformers/main_classes/trainer#api-reference%20][%20transformers.Trainer) from the `transformers` library, passing the `model`, `args`, `tokenizer` and datasets for training and inference. Then, call the [`Trainer.train()` method](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Trainer.train) to start the fine-tuning process.\n",
    "\n",
    "> Note: this process may take up to several hours, depending on your hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "tZVjfPfuYdFF",
    "outputId": "bcd45043-85ba-4910-9b18-2770a1bbb6a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kris/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 189\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [189/189 1:19:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.418899</td>\n",
       "      <td>0.100751</td>\n",
       "      <td>0.082640</td>\n",
       "      <td>0.084789</td>\n",
       "      <td>0.911883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.388719</td>\n",
       "      <td>0.139374</td>\n",
       "      <td>0.091278</td>\n",
       "      <td>0.093028</td>\n",
       "      <td>0.918254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.380618</td>\n",
       "      <td>0.138709</td>\n",
       "      <td>0.094296</td>\n",
       "      <td>0.097516</td>\n",
       "      <td>0.919700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 4143\n",
      "  Batch size = 16\n",
      "/Users/kris/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kris/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kris/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4143\n",
      "  Batch size = 16\n",
      "/Users/kris/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kris/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kris/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4143\n",
      "  Batch size = 16\n",
      "/Users/kris/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kris/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kris/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=189, training_loss=0.2894454834953187, metrics={'train_runtime': 4807.0499, 'train_samples_per_second': 0.624, 'train_steps_per_second': 0.039, 'total_flos': 138706544862000.0, 'train_loss': 0.2894454834953187, 'epoch': 3.0})"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=small_train_dataset,\n",
    "        eval_dataset=dataset_dev,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=lambda p: compute_metrics(*p, label_list, tokenized_dev)\n",
    "    )\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXZ8ro_iYdFF"
   },
   "source": [
    "Now that you have fine-tuned the model, let's evaluate its performance on the `eval_dataset` that you set when constructing the `Trainer` instance.\n",
    "\n",
    "To evaluate the fine-tuned model, call the [`Trainer.evaluate()` method](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Trainer.evaluate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "XUpcBt68YdFG",
    "outputId": "5c0a3cf9-ebe2-424e-d060-e895b9a3f72b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 4143\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='262' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [259/259 07:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[145], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:2208\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2205\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   2207\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 2208\u001b[0m output \u001b[38;5;241m=\u001b[39m eval_loop(\n\u001b[1;32m   2209\u001b[0m     eval_dataloader,\n\u001b[1;32m   2210\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2211\u001b[0m     \u001b[38;5;66;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;00m\n\u001b[1;32m   2212\u001b[0m     \u001b[38;5;66;03m# self.args.prediction_loss_only\u001b[39;00m\n\u001b[1;32m   2213\u001b[0m     prediction_loss_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2214\u001b[0m     ignore_keys\u001b[38;5;241m=\u001b[39mignore_keys,\n\u001b[1;32m   2215\u001b[0m     metric_key_prefix\u001b[38;5;241m=\u001b[39mmetric_key_prefix,\n\u001b[1;32m   2216\u001b[0m )\n\u001b[1;32m   2218\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   2219\u001b[0m output\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m   2220\u001b[0m     speed_metrics(\n\u001b[1;32m   2221\u001b[0m         metric_key_prefix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2225\u001b[0m     )\n\u001b[1;32m   2226\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:2382\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2379\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   2381\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 2382\u001b[0m loss, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_step(model, inputs, prediction_loss_only, ignore_keys\u001b[38;5;241m=\u001b[39mignore_keys)\n\u001b[1;32m   2384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n\u001b[1;32m   2385\u001b[0m     xm\u001b[38;5;241m.\u001b[39mmark_step()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:2590\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   2588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_labels:\n\u001b[1;32m   2589\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocast_smart_context_manager():\n\u001b[0;32m-> 2590\u001b[0m         loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs, return_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2591\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m   2593\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:1972\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1970\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1971\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1972\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m   1973\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   1974\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   1975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:958\u001b[0m, in \u001b[0;36mDistilBertForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;124;03m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001b[39;00m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    956\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 958\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistilbert(\n\u001b[1;32m    959\u001b[0m     input_ids,\n\u001b[1;32m    960\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    961\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m    962\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m    963\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    964\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    965\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    966\u001b[0m )\n\u001b[1;32m    968\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    970\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(sequence_output)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:549\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[1;32m    550\u001b[0m     x\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m    551\u001b[0m     attn_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    552\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m    553\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    554\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    555\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    556\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:327\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    325\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_state,)\n\u001b[0;32m--> 327\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[1;32m    328\u001b[0m     x\u001b[38;5;241m=\u001b[39mhidden_state, attn_mask\u001b[38;5;241m=\u001b[39mattn_mask, head_mask\u001b[38;5;241m=\u001b[39mhead_mask[i], output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions\n\u001b[1;32m    329\u001b[0m )\n\u001b[1;32m    330\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:271\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# Self-Attention\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[1;32m    272\u001b[0m     query\u001b[38;5;241m=\u001b[39mx,\n\u001b[1;32m    273\u001b[0m     key\u001b[38;5;241m=\u001b[39mx,\n\u001b[1;32m    274\u001b[0m     value\u001b[38;5;241m=\u001b[39mx,\n\u001b[1;32m    275\u001b[0m     mask\u001b[38;5;241m=\u001b[39mattn_mask,\n\u001b[1;32m    276\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m    277\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    278\u001b[0m )\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    280\u001b[0m     sa_output, sa_weights \u001b[38;5;241m=\u001b[39m sa_output  \u001b[38;5;66;03m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:202\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    200\u001b[0m q \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_lin(query))  \u001b[38;5;66;03m# (bs, n_heads, q_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m    201\u001b[0m k \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_lin(key))  \u001b[38;5;66;03m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m v \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_lin(value))  \u001b[38;5;66;03m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m    204\u001b[0m q \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(dim_per_head)  \u001b[38;5;66;03m# (bs, n_heads, q_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m    205\u001b[0m scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(q, k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m))  \u001b[38;5;66;03m# (bs, n_heads, q_length, k_length)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9NFI6DmYdFG"
   },
   "source": [
    "Now that you have fine-tuned your DistilBERT model for semantic role labeling, and evaluated its performance on the development dataset, it's time to infer the argument labels of the test dataset and compute a summary of the performance metrics.\n",
    "\n",
    "First, call the [`Trainer.predict()` method](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Trainer.predict) passing the test dataset. The method returns a tuple consisting of the model's predictions on the test dataset, the labels, and metrics.\n",
    "\n",
    "To compute a summary of the model's perfomance metrics on the test dataset, call the `compute_metrics()` function, including:\n",
    "\n",
    "| Parameter name     | Required | Parameter description |\n",
    "|--------------------|:--------------:|-------------|\n",
    "| *positional 1* (`np.ndarray`) | ✅️ | The array of predictions as returned from the `Trainer.predict()` method. |\n",
    "| *positional 2* (`np.ndarray`) | ✅️ | The array of argument labels as returned from the `Trainer.predict()` method. |\n",
    "| *positional 3* (list of strings) | ✅️ | The list of argument labels as strings. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "tMNBhvOcYdFG",
    "outputId": "a03b474b-d546-4d45-f4dd-81992dcdcb58"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 4143\n",
      "  Batch size = 16\n",
      "/Users/kris/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kris/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kris/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(dataset_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def compute_metrics(predictions, labels, label_list, tokenized_dataset, tokenizer, dev_data):\n",
    "    \"\"\"\n",
    "    Compute evaluation metrics for Semantic Role Labeling (SRL).\n",
    "    Return a dictionary with evaluation metrics.\n",
    "    \"\"\"\n",
    "    # The prediction with the highest probability is the predicted label.\n",
    "    predictions_argmax = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Create empty lists for the predictions and true labels.\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    # Iterate over the predictions and true labels, every iteration is one sentence.\n",
    "    for sentence_nr, (prediction, label) in enumerate(zip(predictions_argmax, labels)):\n",
    "\n",
    "        filtered_prediction = []\n",
    "        filtered_label = []\n",
    "\n",
    "        # Get the token-to-word mapping, tokens and sentence for the current sentence.\n",
    "        token_to_word_mapping = tokenized_dataset.word_ids(sentence_nr)\n",
    "        tokens = tokenizer.convert_ids_to_tokens(tokenized_dataset[\"input_ids\"][sentence_nr])\n",
    "        sentence = dev_data.input_form[sentence_nr]\n",
    "    \n",
    "        # Iterate over the predictions and true labels, every iteration is one token.\n",
    "        for token_nr, (p, l, t2w_map, t) in enumerate(zip(prediction, label, token_to_word_mapping, tokens)):\n",
    "\n",
    "            # Find the word that the current token belongs to.\n",
    "            word = sentence[t2w_map] if t2w_map != None else \"\"\n",
    "\n",
    "            # Print the prediction, label, token-to-word mapping, token and word.\n",
    "            # print(f\"p: {p}, l: {l}, t2w_map: {t2w_map}, t: {t}, w: {word}\")\n",
    "            \n",
    "            # Skip the first [CLS] token.\n",
    "            if t == \"[CLS]\":\n",
    "                continue\n",
    "\n",
    "            # If the token is the [SEP] token, break the loop.\n",
    "            if t == \"[SEP]\":\n",
    "                break\n",
    "\n",
    "            # Check if this token belongs to the same word as the previous token.\n",
    "            if t2w_map == token_to_word_mapping[token_nr - 1]:\n",
    "                print(\"same as last! {t2w_map} {token_to_word_mapping[token_nr - 1]}\")\n",
    "                continue\n",
    "            \n",
    "            # Append the prediction and label to the filtered lists.\n",
    "            filtered_prediction.append(label_list[p])\n",
    "            filtered_label.append(label_list[l])\n",
    "    \n",
    "        predictions.append(filtered_prediction)\n",
    "        true_labels.append(filtered_label)\n",
    "\n",
    "    # Flatten the predictions and true labels to compute the metrics.\n",
    "    predict = [label for sentence in predictions for label in sentence]\n",
    "    gold = [label for sentence in true_labels for label in sentence]\n",
    "\n",
    "    print(len(predict))\n",
    "    print(len(gold))\n",
    "\n",
    "    # Create a list of all possible labels from gold and inferenced labels.\n",
    "    labels=list(set(predict+gold))\n",
    "\n",
    "    report = classification_report(gold,predict,target_names=labels,output_dict=True)\n",
    "\n",
    "    # Print the classification report.\n",
    "    print(classification_report(gold,predict))\n",
    "\n",
    "    return {\n",
    "           \"precision\": report[\"macro avg\"][\"precision\"],\n",
    "    \"recall\": report[\"macro avg\"][\"recall\"],\n",
    "    \"f1\": report[\"macro avg\"][\"f1-score\"],\n",
    "    \"accuracy\": report[\"accuracy\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From', 'the', 'AP', 'comes', 'this', 'story', ':', '[SEP]', 'comes']\n"
     ]
    }
   ],
   "source": [
    "print(dev_data.input_form[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87697\n",
      "87697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kris/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kris/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kris/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kris/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/kris/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ARG0       0.65      0.69      0.67      1733\n",
      "        ARG1       0.52      0.65      0.58      3325\n",
      "        ARG2       0.62      0.22      0.32      1212\n",
      "        ARG3       0.00      0.00      0.00        77\n",
      "        ARG4       0.00      0.00      0.00        47\n",
      "        ARG5       0.00      0.00      0.00         1\n",
      "    ARGM-ADJ       0.00      0.00      0.00       251\n",
      "    ARGM-ADV       0.20      0.00      0.01       481\n",
      "    ARGM-CAU       0.00      0.00      0.00        70\n",
      "    ARGM-COM       0.00      0.00      0.00        14\n",
      "    ARGM-CXN       0.00      0.00      0.00        14\n",
      "    ARGM-DIR       0.00      0.00      0.00        48\n",
      "    ARGM-DIS       0.80      0.02      0.04       186\n",
      "    ARGM-EXT       0.00      0.00      0.00       113\n",
      "    ARGM-GOL       0.00      0.00      0.00        26\n",
      "    ARGM-LOC       0.00      0.00      0.00       242\n",
      "    ARGM-LVB       0.00      0.00      0.00        75\n",
      "    ARGM-MNR       0.00      0.00      0.00       175\n",
      "    ARGM-MOD       0.78      0.78      0.78       377\n",
      "    ARGM-NEG       0.80      0.73      0.76       215\n",
      "    ARGM-PRD       0.00      0.00      0.00        50\n",
      "    ARGM-PRP       0.00      0.00      0.00        61\n",
      "    ARGM-PRR       0.00      0.00      0.00        75\n",
      "    ARGM-REC       0.00      0.00      0.00         4\n",
      "    ARGM-TMP       0.74      0.10      0.17       552\n",
      "      C-ARG0       0.00      0.00      0.00         4\n",
      "      C-ARG1       0.00      0.00      0.00        53\n",
      "      C-ARG2       0.00      0.00      0.00         7\n",
      "      C-ARG3       0.00      0.00      0.00         7\n",
      "  C-ARGM-CXN       0.00      0.00      0.00         7\n",
      "  C-ARGM-EXT       0.00      0.00      0.00         2\n",
      "  C-ARGM-LOC       0.00      0.00      0.00         3\n",
      "  C-ARGM-MNR       0.00      0.00      0.00         1\n",
      "      R-ARG0       0.00      0.00      0.00        60\n",
      "      R-ARG1       0.00      0.00      0.00        66\n",
      "      R-ARG2       0.00      0.00      0.00         4\n",
      "      R-ARG3       0.00      0.00      0.00         1\n",
      "  R-ARGM-ADV       0.00      0.00      0.00         1\n",
      "  R-ARGM-CAU       0.00      0.00      0.00         1\n",
      "  R-ARGM-COM       0.00      0.00      0.00         1\n",
      "  R-ARGM-LOC       0.00      0.00      0.00        10\n",
      "  R-ARGM-MNR       0.00      0.00      0.00         2\n",
      "  R-ARGM-TMP       0.00      0.00      0.00         8\n",
      "           _       0.95      0.98      0.97     78035\n",
      "\n",
      "    accuracy                           0.92     87697\n",
      "   macro avg       0.14      0.09      0.10     87697\n",
      "weighted avg       0.90      0.92      0.91     87697\n",
      "\n",
      "{'precision': 0.13797217282841173, 'recall': 0.09478223298676114, 'f1': 0.09785005650428666, 'accuracy': 0.9224944981014174}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kris/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "results = compute_metrics(predictions, labels, label_list, tokenized_dev, tokenizer, dev_data)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrvtvLY9YdFG"
   },
   "source": [
    "Writing the predictions together with the gold labels to a csv file with the function `write_predictions_to_csv` so that the metrics per class can be computed with the `compute_evaluation_metrics_from_csv` function.\n",
    "\n",
    "Now that you have succesfully fine-tuned a model and inferred the argument labels of the test set, let's store the results on disc in a CSV file, and create a full classification report.\n",
    "\n",
    "To write the predictions to CSV, call the `write_predictions_to_csv()` function, including:\n",
    "\n",
    "| Parameter name     | Required | Parameter description |\n",
    "|--------------------|:--------------:|-------------|\n",
    "| *positional 1* (`np.ndarray`) | ✅️ | The array of predictions as returned from the `Trainer.predict()` method. |\n",
    "| *positional 2* (`np.ndarray`) | ✅️ | The array of argument labels as returned from the `Trainer.predict()` method. |\n",
    "| *positional 3* (list of strings) | ✅️ | The list of argument labels as strings. |\n",
    "| *positional 3* (string) | ✅️ | The filepath to write the results to (in CSV format). |\n",
    "\n",
    "Next, to compute a full classification report of the model's performance on the test dataset, call the `compute_evaluation_metrics_from_csv()` function, including:\n",
    "\n",
    "| Parameter name     | Required | Parameter description |\n",
    "|--------------------|:--------------:|-------------|\n",
    "| *positional 1* (string) | ✅️ | The filepath for the CSV file where the model's predictions are stored. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8J6utkmYdFG",
    "outputId": "39c1b369-1359-41da-c7ac-f49bba6fc138"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ARG0       0.78      0.82      0.80      1899\n",
      "        ARG1       0.76      0.82      0.79      3647\n",
      "    ARG1-DSP       0.00      0.00      0.00         4\n",
      "        ARG2       0.62      0.61      0.62      1285\n",
      "        ARG3       0.00      0.00      0.00        79\n",
      "        ARG4       1.00      0.09      0.16        68\n",
      "        ARG5       0.00      0.00      0.00         1\n",
      "        ARGA       0.00      0.00      0.00         2\n",
      "    ARGM-ADJ       0.66      0.69      0.67       254\n",
      "    ARGM-ADV       0.67      0.39      0.49       526\n",
      "    ARGM-CAU       0.00      0.00      0.00        48\n",
      "    ARGM-COM       0.00      0.00      0.00        16\n",
      "    ARGM-CXN       0.00      0.00      0.00        12\n",
      "    ARGM-DIR       0.33      0.11      0.16        47\n",
      "    ARGM-DIS       0.69      0.59      0.64       196\n",
      "    ARGM-EXT       0.78      0.70      0.74       105\n",
      "    ARGM-GOL       0.00      0.00      0.00        29\n",
      "    ARGM-LOC       0.52      0.46      0.49       259\n",
      "    ARGM-LVB       0.69      0.71      0.70        69\n",
      "    ARGM-MNR       0.49      0.28      0.36       164\n",
      "    ARGM-MOD       0.86      0.97      0.91       468\n",
      "    ARGM-NEG       0.86      0.94      0.90       392\n",
      "    ARGM-PRD       0.00      0.00      0.00        50\n",
      "    ARGM-PRP       0.52      0.20      0.28        82\n",
      "    ARGM-PRR       0.67      0.03      0.05        77\n",
      "    ARGM-TMP       0.70      0.70      0.70       586\n",
      "      C-ARG0       0.00      0.00      0.00         3\n",
      "      C-ARG1       0.00      0.00      0.00        57\n",
      "  C-ARG1-DSP       0.00      0.00      0.00         1\n",
      "      C-ARG2       0.00      0.00      0.00         7\n",
      "      C-ARG3       0.00      0.00      0.00         2\n",
      "  C-ARGM-CXN       0.00      0.00      0.00         5\n",
      "  C-ARGM-LOC       0.00      0.00      0.00         1\n",
      "      R-ARG0       0.86      0.82      0.84        67\n",
      "      R-ARG1       0.68      0.75      0.72        52\n",
      "      R-ARG2       0.00      0.00      0.00         1\n",
      "  R-ARGM-ADJ       0.00      0.00      0.00         1\n",
      "  R-ARGM-ADV       0.00      0.00      0.00         1\n",
      "  R-ARGM-DIR       0.00      0.00      0.00         1\n",
      "  R-ARGM-LOC       0.00      0.00      0.00         9\n",
      "  R-ARGM-MNR       0.00      0.00      0.00         8\n",
      "  R-ARGM-TMP       0.00      0.00      0.00         2\n",
      "           _       0.98      0.98      0.98     82424\n",
      "\n",
      "    accuracy                           0.95     93007\n",
      "   macro avg       0.33      0.27      0.28     93007\n",
      "weighted avg       0.95      0.95      0.95     93007\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "results_file = \"predictions.csv\"\n",
    "write_predictions_to_csv(predictions, labels, label_list, results_file)\n",
    "classification_report = compute_evaluation_metrics_from_csv(\"predictions.csv\")\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rBk6GBWYdFG"
   },
   "source": [
    "Finally, store the `tokenizer`, `trainer` and `model` on disc using their built-in methods. For each method call, pass a string representing the directory to save the object and its configuration to.\n",
    "\n",
    "This let's you use the objects' built-in `from_pretrained()` methods to reload their state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Cni2yCZiYdFG"
   },
   "outputs": [],
   "source": [
    "# Use these codes to save model:\n",
    "tokenizer.save_pretrained(\"tokenizer.save_pretrained.distillbert-base-uncased-finetuned-srl\")\n",
    "trainer.save_model(\"trainer.save_model.distillbert-base-uncased-finetuned-srl\")\n",
    "model.save_pretrained(\"model.save_pretrained.distillbert-base-uncased-finetuned-srl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVl8CGcAapSx"
   },
   "source": [
    "If you are running this notebook in Google colab, create a directory in your Google Drive and copy the `tokenizer`, `trainer`, and `model` to your Google Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "avWiTIQcjubr"
   },
   "outputs": [],
   "source": [
    "if runs_in_colab:\n",
    "    !mkdir -p \"/content/drive/MyDrive/NLP_3_baseline_model/model\"\n",
    "    !cp -r '/content/trainer.save_model.distillbert-base-uncased-finetuned-srl' '/content/drive/MyDrive/NLP_3_baseline_model/model'\n",
    "    !cp -r '/content/model.save_pretrained.distillbert-base-uncased-finetuned-srl' '/content/drive/MyDrive/NLP_3_baseline_model/model'\n",
    "    !cp -r '/content/tokenizer.save_pretrained.distillbert-base-uncased-finetuned-srl' '/content/drive/MyDrive/NLP_3_baseline_model/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUYZ6_djl3mh",
    "outputId": "c4db77f5-9e15-4dd5-acb3-7cfe368d2029"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ARG0       0.79      0.82      0.80      1899\n",
      "        ARG1       0.75      0.83      0.79      3647\n",
      "    ARG1-DSP       0.00      0.00      0.00         4\n",
      "        ARG2       0.60      0.65      0.62      1285\n",
      "        ARG3       0.00      0.00      0.00        79\n",
      "        ARG4       0.00      0.00      0.00        68\n",
      "        ARG5       0.00      0.00      0.00         1\n",
      "        ARGA       0.00      0.00      0.00         2\n",
      "    ARGM-ADJ       0.68      0.68      0.68       254\n",
      "    ARGM-ADV       0.62      0.41      0.49       526\n",
      "    ARGM-CAU       1.00      0.02      0.04        48\n",
      "    ARGM-COM       0.00      0.00      0.00        16\n",
      "    ARGM-CXN       0.00      0.00      0.00        12\n",
      "    ARGM-DIR       0.27      0.15      0.19        47\n",
      "    ARGM-DIS       0.70      0.56      0.62       196\n",
      "    ARGM-EXT       0.74      0.69      0.71       105\n",
      "    ARGM-GOL       0.00      0.00      0.00        29\n",
      "    ARGM-LOC       0.54      0.48      0.51       259\n",
      "    ARGM-LVB       0.67      0.51      0.58        69\n",
      "    ARGM-MNR       0.47      0.34      0.40       164\n",
      "    ARGM-MOD       0.87      0.95      0.91       468\n",
      "    ARGM-NEG       0.85      0.94      0.90       392\n",
      "    ARGM-PRD       0.00      0.00      0.00        50\n",
      "    ARGM-PRP       0.61      0.23      0.34        82\n",
      "    ARGM-PRR       0.00      0.00      0.00        77\n",
      "    ARGM-TMP       0.71      0.74      0.73       586\n",
      "      C-ARG0       0.00      0.00      0.00         3\n",
      "      C-ARG1       0.00      0.00      0.00        57\n",
      "  C-ARG1-DSP       0.00      0.00      0.00         1\n",
      "      C-ARG2       0.00      0.00      0.00         7\n",
      "      C-ARG3       0.00      0.00      0.00         2\n",
      "  C-ARGM-CXN       0.00      0.00      0.00         5\n",
      "  C-ARGM-LOC       0.00      0.00      0.00         1\n",
      "      R-ARG0       0.83      0.85      0.84        67\n",
      "      R-ARG1       0.60      0.77      0.67        52\n",
      "      R-ARG2       0.00      0.00      0.00         1\n",
      "  R-ARGM-ADJ       0.00      0.00      0.00         1\n",
      "  R-ARGM-ADV       0.00      0.00      0.00         1\n",
      "  R-ARGM-DIR       0.00      0.00      0.00         1\n",
      "  R-ARGM-LOC       0.00      0.00      0.00         9\n",
      "  R-ARGM-MNR       0.00      0.00      0.00         8\n",
      "  R-ARGM-TMP       0.00      0.00      0.00         2\n",
      "           _       0.98      0.98      0.98     82424\n",
      "\n",
      "    accuracy                           0.95     93007\n",
      "   macro avg       0.31      0.27      0.27     93007\n",
      "weighted avg       0.95      0.95      0.95     93007\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "classification_report = compute_evaluation_metrics_from_csv(\"predictions-adv.csv\")\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of the basic model\n",
    "\n",
    "In the basic model, input sequences start with the token ID for the `[CLS]` token, followed by the tokenized sentence, the `[SEP]` token, the predicate, and a final `[SEP]` token. However, this method introduces ambiguity when there are multiple word forms in a sentence that are identical to the predicate word form, for example:\n",
    "\n",
    "```\n",
    "['[CLS]', 'she', 'saw', 'a', 'man', 'saw', 'a', 'tree', '[SEP]', 'saw', '[SEP]']\n",
    "```\n",
    "\n",
    "In the sentence above, the predicate word form 'saw' occurs twice in the sentence, with different frames and arguments for each occurence:\n",
    "1. In the first occurence, the frame evoked is that of [`see.01` *(view)*](https://propbank.github.io/v3.4.0/frames/see.html#see.01), which has the following arguments:\n",
    "\n",
    "    - `ARG0-PAG`: viewer\n",
    "    - `ARG1-PPT`: thing viewed\n",
    "    - `ARG2-PRD`: attribute of arg1, further description\n",
    "\n",
    "  - In this frame, 'she' is labeled `ARG0` and 'man' is labeled `ARG1`.\n",
    "\n",
    "2. In the second occurence, the frame evoked is that of [`saw.06` *(cut with a saw)*](https://propbank.github.io/v3.4.0/frames/see.html#saw.06), which has the following arguments:\n",
    "\n",
    "    - `ARG0-PAG`: cutter\n",
    "    - `ARG1-PPT`: thing cut\n",
    "    - `ARG2-SRC`: Cut from what? source \n",
    "\n",
    "  - In this frame, 'man' is labeled `ARG0` and 'tree' is labeled `ARG1`.\n",
    "\n",
    "Due to limitations in how your basic model represents these input sequences, the model isn't able to disambiguate between the two frames in the sentence above, introducing noise in the model. \n",
    "\n",
    "## Advanced model\n",
    "\n",
    "To resolve the limitation of the basic model, you're going to create an advanced model, using a more sophisticated representation of the input sequnece. Instead of providing just the predicate between `[SEP]` tokens, you're going to provide a context window for the predicate. \n",
    "\n",
    "This context helps the model disambiguate between the different word forms identical to the predicate word forms. The size of the context window is 3 words, meaning that alongside the predicate, its preceding and following word and put between the `[SEP]` tokens. For example, for the first occurence of 'saw', you'll create the following input sequence:\n",
    "\n",
    "```\n",
    "['[CLS]', 'she', 'saw', 'a', 'man', 'saw', 'a', 'tree', '[SEP]', 'she', 'saw', 'a' '[SEP]']\n",
    "```\n",
    "\n",
    "For the second occurence of 'saw', you'll create the following input sequence:\n",
    "\n",
    "```\n",
    "['[CLS]', 'she', 'saw', 'a', 'man', 'saw', 'a', 'tree', '[SEP]', 'man', 'saw', 'a' '[SEP]']\n",
    "```\n",
    "\n",
    "Using this context window, your model can learn to disambiguate between both occurences, reducing noise in the fine-tuning and (hopefully) improving the model's performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'define_args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m args \u001b[38;5;241m=\u001b[39m define_args(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madvanced\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'define_args' is not defined"
     ]
    }
   ],
   "source": [
    "args = define_args(mode='advanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(args,mode='advanced', data_range=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations in the advanced model\n",
    "\n",
    "Although the advanced model's representation addresses the issue of predicate ambiguity, it does not provide additional information about the tokens and their probable semantic role. Such representations do not entail explicit feature-based information depicting the relations between the predicate and the tokens, thus token classification is dependent on the prertained encodings of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The results show that the advanced model did not actually manage to improve the performance of the basic model. Both models seem to perform similarly on the more frequent argument labels like ARG0, ARG1, and ARGM-MOD, showing that adding the addition of the context window does not itself suffice to significantly change how the model handles even the most frequent labels. Also, although the model shows slight improvements in some labels (e.g., ARG2's recall increases from 0.61 to 0.65), at the same time it also negatively impacts the performance of others (e.g., ARGM-ADV's precision decreases from 0.67 to 0.62). Overall, both models’ low performance could be partially attributed to the fact that the latter were trained on only one epoch, depriving them from the chance to learn more nuanced insights and to a further extend benefit from the addition of extra contextual information surrounding the predicate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and future research\n",
    "\n",
    "The results show that the baseline model, taking just the predicate, performs better than the advanced model. It is likely that the context window is not meaningful enough for the model to predict the correct arguments for semantic role labeling.\n",
    "\n",
    "It is important to consider that the labels are assigned in terms of the subtokens fed to the transformer model, rather than the token itself, which might significantly impact the results. Future experiments should consider counting the label assigned to the token to evaluate the model's performance.\n",
    "\n",
    "Additionally, future research should focus on different ways to provide a meaningful representation of the predicate to the model, making it robust enough for the semantic role labeling task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGd8F8QGYdFH"
   },
   "source": [
    "## Group Contribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HHdp36FYdFH"
   },
   "source": [
    "##### Ariana Britez:\n",
    "- functions to map the labels to number for model input: get_label_mapping, map_labels_to_numbers, map_labels_in_dataframe\n",
    "- function to get the list of labels for model input: get_labels_from_map\n",
    "- function to compute the metrics during training, evaluation and inference: compute_metrics, compute_evaluation_metrics_from_csv\n",
    "- function to load the transformer model for fine-tuning: load_srl_model\n",
    "- function to load the dataset in format that model can handle: load_dataset\n",
    "- function to save the model predictions with gold labels for evaluation: write_predictions_to_csv\n",
    "- writing markdown from importing the model section until evaluation of the baseline model\n",
    "- conclusion and future research\n",
    "\n",
    "##### Kris Stallenberg:\n",
    "- Writing tutorial-style documentation for the full pipeline.\n",
    "- Adding print statements throughout the notebook clarifying the data structures.\n",
    "- Explain the limitations of the basic model and how the advanced model solves these.\n",
    "- Refactoring functions in the utils.py module.\n",
    "\n",
    "##### Farnaz Bani Fatemi:\n",
    "- Helping in preprocessing of data and fine tuning baseline model and tokenizer.\n",
    "- Function to load and represent data for baseline model input form and extract gold arguments: read_data_as_sentence.\n",
    "- Function to tokenize input form and assign each token label to its subtokens: tokenize_and_align_labels.\n",
    "- Cell in main.ipynb to locally save fine-tuned model.\n",
    "- Adding some commands to run code in colab.\n",
    "- Testing some codes to help fix debugs and issues for models.\n",
    "\n",
    "##### Szabolcs Pal\n",
    "- Helped in preprocessing the data for advanced model\n",
    "- Limitations and explanation of advanced model\n",
    "- Main function used for advanced model\n",
    "- Attemped to do postprocessing on the subtokens of the model output\n",
    "\n",
    "##### Christina Karavida\n",
    "- Worked on the baseline model (run into issues in the evaluation stage)\n",
    "- Also created a version of the main function for the advanced model       \n",
    "- Explained the results for the two models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kd5G74joapSx"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
