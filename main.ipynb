{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic role labeling with BERT\n",
    "\n",
    "In this notebook, you'll perform semantic role labeling with BERT, using the Universal Propbank dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin\n",
    "\n",
    "### Install libraries\n",
    "\n",
    "Uncomment and run the following cells to install the required pip packages, for example when running the notebook in [colab](https://colab.research.google.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install seqeval\n",
    "# !pip install accelerate==0.21.0\n",
    "# !pip install transformers[torch]\n",
    "# !pip install accelerate -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer,AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
    "from datasets import Dataset\n",
    "from utils import read_data_as_sentence,map_labels_in_dataframe,tokenize_and_align_labels,get_label_mapping,get_labels_from_map,load_srl_model,load_dataset,compute_metrics,write_predictions_to_csv,compute_evaluation_metrics_from_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can train the model, you need to extract sentences from the training, development and test datasets, and preprocess the sentences.\n",
    "\n",
    "To preprocess the datase and save the resulting DataFrame to a file, call the `read_data_as_sentence()` function, including:\n",
    "\n",
    "| Parameter name     | Required | Parameter description |\n",
    "|--------------------|:--------------:|-------------|\n",
    "| *positional 1*                   | ✅️ | The filepath for the CoNNLU dataset. |\n",
    "| *positional 2*                 | ✅ | The filepath to write the preprocessed DataFrame to. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data_as_sentence('data/en_ewt-up-train.conllu', 'data/en_ewt-up-train.preprocessed.csv')\n",
    "dev_data = read_data_as_sentence('data/en_ewt-up-dev.conllu', 'data/en_ewt-up-dev.preprocessed.csv')\n",
    "test_data = read_data_as_sentence('data/en_ewt-up-test.conllu', 'data/en_ewt-up-test.preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `read_data_as_sentence()` function returns DataFrames, where each row represents a sentence from the dataset passed to the function. Each sentence has been expanded based on its predicates, resulting in multiple copies of the same sentence, each focused on a different predicate.\n",
    "\n",
    "The DataFrame has two columns:\n",
    "\n",
    "- `input_form`: a list of strings, where each string represents a words in the sentence, followed by two special tokens:\n",
    "    1. A special token (`[SEP]`), which denotes the separation between the words of the sentence and the predicate form. \n",
    "    2. The predicate form, which corresponds to the `argument` values for the same row in the DataFrame.\n",
    "- `argument`: a list of strings, representing the arguments associated with each word in the sentence. The length of each list is equal to the number of words in the sentence, plus two additional elements, for the special token and predicate form. The arguments match the predicate appended to the `input_form` for the same row in the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the DataFrame\n",
    "\n",
    "To explore the DataFrame, print the head of the preprocessed DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4799 entries, 0 to 4798\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   input_form  4799 non-null   object\n",
      " 1   argument    4799 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 75.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(test_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Non-Null** count for both columns should match, indicating there are as many lists of `input_form` values as there are lists of `argument` values.\n",
    "\n",
    "Next, print the words and their argument labels for the first 20 sentences of the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "form: What            argument: _\n",
      "form: if              argument: _\n",
      "form: Google          argument: ARG1\n",
      "form: Morphed         argument: _\n",
      "form: Into            argument: _\n",
      "form: GoogleOS        argument: ARG2\n",
      "form: ?               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: Morphed         argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: What            argument: _\n",
      "form: if              argument: _\n",
      "form: Google          argument: ARG0\n",
      "form: expanded        argument: _\n",
      "form: on              argument: _\n",
      "form: its             argument: _\n",
      "form: search          argument: _\n",
      "form: -               argument: _\n",
      "form: engine          argument: _\n",
      "form: (               argument: _\n",
      "form: and             argument: _\n",
      "form: now             argument: _\n",
      "form: e-mail          argument: _\n",
      "form: )               argument: _\n",
      "form: wares           argument: ARG1\n",
      "form: into            argument: _\n",
      "form: a               argument: _\n",
      "form: full            argument: _\n",
      "form: -               argument: _\n",
      "form: fledged         argument: _\n",
      "form: operating       argument: _\n",
      "form: system          argument: ARG4\n",
      "form: ?               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: expanded        argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: (               argument: _\n",
      "form: And             argument: _\n",
      "form: ,               argument: _\n",
      "form: by              argument: _\n",
      "form: the             argument: _\n",
      "form: way             argument: _\n",
      "form: ,               argument: _\n",
      "form: is              argument: _\n",
      "form: anybody         argument: _\n",
      "form: else            argument: _\n",
      "form: just            argument: _\n",
      "form: a               argument: _\n",
      "form: little          argument: _\n",
      "form: nostalgic       argument: _\n",
      "form: for             argument: _\n",
      "form: the             argument: _\n",
      "form: days            argument: _\n",
      "form: when            argument: _\n",
      "form: that            argument: _\n",
      "form: was             argument: _\n",
      "form: a               argument: _\n",
      "form: good            argument: _\n",
      "form: thing           argument: _\n",
      "form: ?               argument: _\n",
      "form: )               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: way             argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: (               argument: _\n",
      "form: And             argument: _\n",
      "form: ,               argument: _\n",
      "form: by              argument: _\n",
      "form: the             argument: _\n",
      "form: way             argument: ARGM-DIS\n",
      "form: ,               argument: _\n",
      "form: is              argument: _\n",
      "form: anybody         argument: ARG1\n",
      "form: else            argument: _\n",
      "form: just            argument: _\n",
      "form: a               argument: _\n",
      "form: little          argument: _\n",
      "form: nostalgic       argument: ARG2\n",
      "form: for             argument: _\n",
      "form: the             argument: _\n",
      "form: days            argument: _\n",
      "form: when            argument: _\n",
      "form: that            argument: _\n",
      "form: was             argument: _\n",
      "form: a               argument: _\n",
      "form: good            argument: _\n",
      "form: thing           argument: _\n",
      "form: ?               argument: _\n",
      "form: )               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: is              argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: (               argument: _\n",
      "form: And             argument: _\n",
      "form: ,               argument: _\n",
      "form: by              argument: _\n",
      "form: the             argument: _\n",
      "form: way             argument: _\n",
      "form: ,               argument: _\n",
      "form: is              argument: _\n",
      "form: anybody         argument: _\n",
      "form: else            argument: _\n",
      "form: just            argument: _\n",
      "form: a               argument: _\n",
      "form: little          argument: _\n",
      "form: nostalgic       argument: _\n",
      "form: for             argument: _\n",
      "form: the             argument: _\n",
      "form: days            argument: ARGM-TMP\n",
      "form: when            argument: R-ARGM-TMP\n",
      "form: that            argument: ARG1\n",
      "form: was             argument: _\n",
      "form: a               argument: _\n",
      "form: good            argument: _\n",
      "form: thing           argument: ARG2\n",
      "form: ?               argument: _\n",
      "form: )               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: is              argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: This            argument: _\n",
      "form: BuzzMachine     argument: ARG2\n",
      "form: post            argument: _\n",
      "form: argues          argument: _\n",
      "form: that            argument: _\n",
      "form: Google          argument: _\n",
      "form: 's              argument: _\n",
      "form: rush            argument: _\n",
      "form: toward          argument: _\n",
      "form: ubiquity        argument: _\n",
      "form: might           argument: _\n",
      "form: backfire        argument: _\n",
      "form: --              argument: _\n",
      "form: which           argument: _\n",
      "form: we              argument: _\n",
      "form: 've             argument: _\n",
      "form: all             argument: _\n",
      "form: heard           argument: _\n",
      "form: before          argument: _\n",
      "form: ,               argument: _\n",
      "form: but             argument: _\n",
      "form: it              argument: _\n",
      "form: 's              argument: _\n",
      "form: particularly    argument: _\n",
      "form: well            argument: _\n",
      "form: -               argument: _\n",
      "form: put             argument: _\n",
      "form: in              argument: _\n",
      "form: this            argument: _\n",
      "form: post            argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: post            argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: This            argument: _\n",
      "form: BuzzMachine     argument: _\n",
      "form: post            argument: ARG0\n",
      "form: argues          argument: _\n",
      "form: that            argument: _\n",
      "form: Google          argument: _\n",
      "form: 's              argument: _\n",
      "form: rush            argument: _\n",
      "form: toward          argument: _\n",
      "form: ubiquity        argument: _\n",
      "form: might           argument: _\n",
      "form: backfire        argument: ARG1\n",
      "form: --              argument: _\n",
      "form: which           argument: _\n",
      "form: we              argument: _\n",
      "form: 've             argument: _\n",
      "form: all             argument: _\n",
      "form: heard           argument: _\n",
      "form: before          argument: _\n",
      "form: ,               argument: _\n",
      "form: but             argument: _\n",
      "form: it              argument: _\n",
      "form: 's              argument: _\n",
      "form: particularly    argument: _\n",
      "form: well            argument: _\n",
      "form: -               argument: _\n",
      "form: put             argument: _\n",
      "form: in              argument: _\n",
      "form: this            argument: _\n",
      "form: post            argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: argues          argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: This            argument: _\n",
      "form: BuzzMachine     argument: _\n",
      "form: post            argument: _\n",
      "form: argues          argument: _\n",
      "form: that            argument: _\n",
      "form: Google          argument: ARG1\n",
      "form: 's              argument: _\n",
      "form: rush            argument: _\n",
      "form: toward          argument: _\n",
      "form: ubiquity        argument: ARG2\n",
      "form: might           argument: _\n",
      "form: backfire        argument: _\n",
      "form: --              argument: _\n",
      "form: which           argument: _\n",
      "form: we              argument: _\n",
      "form: 've             argument: _\n",
      "form: all             argument: _\n",
      "form: heard           argument: _\n",
      "form: before          argument: _\n",
      "form: ,               argument: _\n",
      "form: but             argument: _\n",
      "form: it              argument: _\n",
      "form: 's              argument: _\n",
      "form: particularly    argument: _\n",
      "form: well            argument: _\n",
      "form: -               argument: _\n",
      "form: put             argument: _\n",
      "form: in              argument: _\n",
      "form: this            argument: _\n",
      "form: post            argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: rush            argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: This            argument: _\n",
      "form: BuzzMachine     argument: _\n",
      "form: post            argument: _\n",
      "form: argues          argument: _\n",
      "form: that            argument: _\n",
      "form: Google          argument: _\n",
      "form: 's              argument: _\n",
      "form: rush            argument: ARG1\n",
      "form: toward          argument: _\n",
      "form: ubiquity        argument: _\n",
      "form: might           argument: ARGM-MOD\n",
      "form: backfire        argument: _\n",
      "form: --              argument: _\n",
      "form: which           argument: _\n",
      "form: we              argument: _\n",
      "form: 've             argument: _\n",
      "form: all             argument: _\n",
      "form: heard           argument: ARGM-ADV\n",
      "form: before          argument: _\n",
      "form: ,               argument: _\n",
      "form: but             argument: _\n",
      "form: it              argument: _\n",
      "form: 's              argument: _\n",
      "form: particularly    argument: _\n",
      "form: well            argument: _\n",
      "form: -               argument: _\n",
      "form: put             argument: _\n",
      "form: in              argument: _\n",
      "form: this            argument: _\n",
      "form: post            argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: backfire        argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: This            argument: _\n",
      "form: BuzzMachine     argument: _\n",
      "form: post            argument: _\n",
      "form: argues          argument: _\n",
      "form: that            argument: _\n",
      "form: Google          argument: _\n",
      "form: 's              argument: _\n",
      "form: rush            argument: _\n",
      "form: toward          argument: _\n",
      "form: ubiquity        argument: _\n",
      "form: might           argument: _\n",
      "form: backfire        argument: _\n",
      "form: --              argument: _\n",
      "form: which           argument: _\n",
      "form: we              argument: _\n",
      "form: 've             argument: _\n",
      "form: all             argument: _\n",
      "form: heard           argument: _\n",
      "form: before          argument: _\n",
      "form: ,               argument: _\n",
      "form: but             argument: _\n",
      "form: it              argument: _\n",
      "form: 's              argument: _\n",
      "form: particularly    argument: _\n",
      "form: well            argument: _\n",
      "form: -               argument: _\n",
      "form: put             argument: _\n",
      "form: in              argument: _\n",
      "form: this            argument: _\n",
      "form: post            argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: 've             argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: This            argument: _\n",
      "form: BuzzMachine     argument: _\n",
      "form: post            argument: _\n",
      "form: argues          argument: _\n",
      "form: that            argument: _\n",
      "form: Google          argument: _\n",
      "form: 's              argument: _\n",
      "form: rush            argument: _\n",
      "form: toward          argument: _\n",
      "form: ubiquity        argument: _\n",
      "form: might           argument: _\n",
      "form: backfire        argument: _\n",
      "form: --              argument: _\n",
      "form: which           argument: ARG1\n",
      "form: we              argument: ARG0\n",
      "form: 've             argument: _\n",
      "form: all             argument: ARGM-ADV\n",
      "form: heard           argument: _\n",
      "form: before          argument: ARGM-TMP\n",
      "form: ,               argument: _\n",
      "form: but             argument: _\n",
      "form: it              argument: _\n",
      "form: 's              argument: _\n",
      "form: particularly    argument: _\n",
      "form: well            argument: _\n",
      "form: -               argument: _\n",
      "form: put             argument: _\n",
      "form: in              argument: _\n",
      "form: this            argument: _\n",
      "form: post            argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: heard           argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: This            argument: _\n",
      "form: BuzzMachine     argument: _\n",
      "form: post            argument: _\n",
      "form: argues          argument: _\n",
      "form: that            argument: _\n",
      "form: Google          argument: _\n",
      "form: 's              argument: _\n",
      "form: rush            argument: _\n",
      "form: toward          argument: _\n",
      "form: ubiquity        argument: _\n",
      "form: might           argument: _\n",
      "form: backfire        argument: _\n",
      "form: --              argument: _\n",
      "form: which           argument: _\n",
      "form: we              argument: _\n",
      "form: 've             argument: _\n",
      "form: all             argument: _\n",
      "form: heard           argument: _\n",
      "form: before          argument: _\n",
      "form: ,               argument: _\n",
      "form: but             argument: _\n",
      "form: it              argument: ARG1\n",
      "form: 's              argument: _\n",
      "form: particularly    argument: ARGM-ADV\n",
      "form: well            argument: _\n",
      "form: -               argument: _\n",
      "form: put             argument: ARG2\n",
      "form: in              argument: _\n",
      "form: this            argument: _\n",
      "form: post            argument: ARGM-LOC\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: 's              argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: This            argument: _\n",
      "form: BuzzMachine     argument: _\n",
      "form: post            argument: _\n",
      "form: argues          argument: _\n",
      "form: that            argument: _\n",
      "form: Google          argument: _\n",
      "form: 's              argument: _\n",
      "form: rush            argument: _\n",
      "form: toward          argument: _\n",
      "form: ubiquity        argument: _\n",
      "form: might           argument: _\n",
      "form: backfire        argument: _\n",
      "form: --              argument: _\n",
      "form: which           argument: _\n",
      "form: we              argument: _\n",
      "form: 've             argument: _\n",
      "form: all             argument: _\n",
      "form: heard           argument: _\n",
      "form: before          argument: _\n",
      "form: ,               argument: _\n",
      "form: but             argument: _\n",
      "form: it              argument: _\n",
      "form: 's              argument: _\n",
      "form: particularly    argument: _\n",
      "form: well            argument: _\n",
      "form: -               argument: _\n",
      "form: put             argument: _\n",
      "form: in              argument: _\n",
      "form: this            argument: _\n",
      "form: post            argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: post            argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: Google          argument: ARG1\n",
      "form: is              argument: _\n",
      "form: a               argument: _\n",
      "form: nice            argument: _\n",
      "form: search          argument: _\n",
      "form: engine          argument: ARG2\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: is              argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: Does            argument: _\n",
      "form: anybody         argument: _\n",
      "form: use             argument: _\n",
      "form: it              argument: _\n",
      "form: for             argument: _\n",
      "form: anything        argument: _\n",
      "form: else            argument: _\n",
      "form: ?               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: Does            argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: Does            argument: _\n",
      "form: anybody         argument: ARG0\n",
      "form: use             argument: _\n",
      "form: it              argument: ARG1\n",
      "form: for             argument: _\n",
      "form: anything        argument: ARG2\n",
      "form: else            argument: _\n",
      "form: ?               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: use             argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: They            argument: ARG0\n",
      "form: own             argument: _\n",
      "form: blogger         argument: ARG1\n",
      "form: ,               argument: _\n",
      "form: of              argument: ARGM-ADV\n",
      "form: course          argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: own             argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: Is              argument: _\n",
      "form: that            argument: ARG1\n",
      "form: a               argument: _\n",
      "form: money           argument: _\n",
      "form: maker           argument: ARG2\n",
      "form: ?               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: Is              argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: I               argument: _\n",
      "form: 'm              argument: _\n",
      "form: staying         argument: _\n",
      "form: away            argument: _\n",
      "form: from            argument: _\n",
      "form: the             argument: _\n",
      "form: stock           argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: 'm              argument: None\n",
      "\n",
      "========================================\n",
      "\n",
      "form: I               argument: ARG1\n",
      "form: 'm              argument: _\n",
      "form: staying         argument: _\n",
      "form: away            argument: ARG3\n",
      "form: from            argument: _\n",
      "form: the             argument: _\n",
      "form: stock           argument: _\n",
      "form: .               argument: _\n",
      "----------------------------------------\n",
      "form: [SEP]           argument: None\n",
      "form: staying         argument: None\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for form, argument in zip(test_data.input_form[:20], test_data.argument[:20]):\n",
    "    for f, a in zip(form, argument):\n",
    "        if f == '[SEP]':\n",
    "            print('-' * 40)\n",
    "        print(f\"form: {f:<15} argument: {a}\")\n",
    "    print('\\n' + '=' * 40 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import the BERT model and tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use HuggingFace's [`AutoTokenizer`](https://huggingface.co/docs/transformers/v4.38.2/en/model_doc/auto#transformers.AutoTokenizer) to construct a DistilBERT tokenizer, which is based on the WordPiece algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model ID to use\n",
    "model_id = \"distilbert-base-uncased\"\n",
    "\n",
    "# Initialize the tokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Check the assertion that the tokenizer is an instance of transformers.PreTrainedTokenizerFast \n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the sentence representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'if', 'Google', 'expanded', 'on', 'its', 'search', '-', 'engine', '(', 'and', 'now', 'e-mail', ')', 'wares', 'into', 'a', 'full', '-', 'fledged', 'operating', 'system', '?', '[SEP]', 'expanded']\n"
     ]
    }
   ],
   "source": [
    "example = test_data['input_form'][1]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentence contains the [SEP] special token followed by the predicate. Therefore, the parameter `add_special_tokens` is set to True so that the index is converted to 102 accordingly and is not treated as another word. \\\n",
    "In addition, the sentence is already split into tokens, to the parameter `is_split_into_words` is also set to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2054, 2065, 8224, 4423, 2006, 2049, 3945, 1011, 3194, 1006, 1998, 2085, 1041, 1011, 5653, 1007, 16283, 2015, 2046, 1037, 2440, 1011, 26712, 4082, 2291, 1029, 102, 4423, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(example,add_special_tokens=True,is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'what', 'if', 'google', 'expanded', 'on', 'its', 'search', '-', 'engine', '(', 'and', 'now', 'e', '-', 'mail', ')', 'ware', '##s', 'into', 'a', 'full', '-', 'fledged', 'operating', 'system', '?', '[SEP]', 'expanded', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenized_input = tokenizer(example,add_special_tokens=True,is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing and preparing input for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the mapping of all possible arguments across all datasets to a numerical value with the `get_label_mapping` function.\\\n",
    "None value stays as None to be mapped to the special token in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = get_label_mapping(train_data, test_data, dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_': 0, 'ARG0': 1, 'ARG1': 2, 'ARG1-DSP': 3, 'ARG2': 4, 'ARG3': 5, 'ARG4': 6, 'ARG5': 7, 'ARGA': 8, 'ARGM-ADJ': 9, 'ARGM-ADV': 10, 'ARGM-CAU': 11, 'ARGM-COM': 12, 'ARGM-CXN': 13, 'ARGM-DIR': 14, 'ARGM-DIS': 15, 'ARGM-EXT': 16, 'ARGM-GOL': 17, 'ARGM-LOC': 18, 'ARGM-LVB': 19, 'ARGM-MNR': 20, 'ARGM-MOD': 21, 'ARGM-NEG': 22, 'ARGM-PRD': 23, 'ARGM-PRP': 24, 'ARGM-PRR': 25, 'ARGM-REC': 26, 'ARGM-TMP': 27, 'C-ARG0': 28, 'C-ARG1': 29, 'C-ARG1-DSP': 30, 'C-ARG2': 31, 'C-ARG3': 32, 'C-ARG4': 33, 'C-ARGM-ADV': 34, 'C-ARGM-COM': 35, 'C-ARGM-CXN': 36, 'C-ARGM-DIR': 37, 'C-ARGM-EXT': 38, 'C-ARGM-GOL': 39, 'C-ARGM-LOC': 40, 'C-ARGM-MNR': 41, 'C-ARGM-PRP': 42, 'C-ARGM-PRR': 43, 'C-ARGM-TMP': 44, 'R-ARG0': 45, 'R-ARG1': 46, 'R-ARG2': 47, 'R-ARG3': 48, 'R-ARG4': 49, 'R-ARGM-ADJ': 50, 'R-ARGM-ADV': 51, 'R-ARGM-CAU': 52, 'R-ARGM-COM': 53, 'R-ARGM-DIR': 54, 'R-ARGM-GOL': 55, 'R-ARGM-LOC': 56, 'R-ARGM-MNR': 57, 'R-ARGM-TMP': 58, None: None}\n"
     ]
    }
   ],
   "source": [
    "print(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the labels in the df to numerical values for the language model with `map_labels_in_dataframe` function. The label_map dictionary from the function above is needed to map the arguments to their value.\\\n",
    "Add a new column to the df matching the arguments to label numbers. 0 stands for '_' (no argument) and the rest of the arguments are alphabetically ordered. \\\n",
    "*None* label will be mapped to the *[SEP]* token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = map_labels_in_dataframe(train_data,label_map)\n",
    "dev_data = map_labels_in_dataframe(dev_data,label_map)\n",
    "test_data = map_labels_in_dataframe(test_data,label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the head to confirm the labels were correctly converted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_form</th>\n",
       "      <th>argument</th>\n",
       "      <th>mapped_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[What, if, Google, Morphed, Into, GoogleOS, ?,...</td>\n",
       "      <td>[_, _, ARG1, _, _, ARG2, _, None, None]</td>\n",
       "      <td>[0, 0, 2, 0, 0, 4, 0, None, None]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[What, if, Google, expanded, on, its, search, ...</td>\n",
       "      <td>[_, _, ARG0, _, _, _, _, _, _, _, _, _, _, _, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(, And, ,, by, the, way, ,, is, anybody, else...</td>\n",
       "      <td>[_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(, And, ,, by, the, way, ,, is, anybody, else...</td>\n",
       "      <td>[_, _, _, _, _, ARGM-DIS, _, _, ARG1, _, _, _,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 15, 0, 0, 2, 0, 0, 0, 0, 4, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(, And, ,, by, the, way, ,, is, anybody, else...</td>\n",
       "      <td>[_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_form  \\\n",
       "0  [What, if, Google, Morphed, Into, GoogleOS, ?,...   \n",
       "1  [What, if, Google, expanded, on, its, search, ...   \n",
       "2  [(, And, ,, by, the, way, ,, is, anybody, else...   \n",
       "3  [(, And, ,, by, the, way, ,, is, anybody, else...   \n",
       "4  [(, And, ,, by, the, way, ,, is, anybody, else...   \n",
       "\n",
       "                                            argument  \\\n",
       "0            [_, _, ARG1, _, _, ARG2, _, None, None]   \n",
       "1  [_, _, ARG0, _, _, _, _, _, _, _, _, _, _, _, ...   \n",
       "2  [_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, ...   \n",
       "3  [_, _, _, _, _, ARGM-DIS, _, _, ARG1, _, _, _,...   \n",
       "4  [_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, ...   \n",
       "\n",
       "                                       mapped_labels  \n",
       "0                  [0, 0, 2, 0, 0, 4, 0, None, None]  \n",
       "1  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 15, 0, 0, 2, 0, 0, 0, 0, 4, 0,...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `tokenize_and_align_labels` function to tokenize train, test, and dev dataframe. Padding is applied to make sure all input is the same length for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test = tokenize_and_align_labels(tokenizer, test_data, label_all_tokens=True)\n",
    "tokenized_train = tokenize_and_align_labels(tokenizer, train_data, label_all_tokens=True)\n",
    "tokenized_dev = tokenize_and_align_labels(tokenizer, dev_data, label_all_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input for the model has the corresponding special token [CLS] followed by the tokenized sentence, the special token [SEP], the predicate and the final [SEP] token. \\\n",
    "The numerical labels to be fed to the model correspond to the tokenized sentence.\\\n",
    "The input is padded so that every vector is of the same length, including the labels and the attention mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'what', 'if', 'google', 'mor', '##ph', '##ed', 'into', 'google', '##os', '?', '[SEP]', 'mor', '##ph', '##ed', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n",
      "tensor([  101,  2054,  2065,  8224, 22822,  8458,  2098,  2046,  8224,  2891,\n",
      "         1029,   102, 22822,  8458,  2098,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0])\n",
      "[-100, 0, 0, 2, 0, 0, 0, 0, 4, 4, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(tokenized_test[\"input_ids\"][0]))\n",
    "print(tokenized_test[\"attention_mask\"][0])\n",
    "print(tokenized_test[\"input_ids\"][0])\n",
    "print(tokenized_test[\"labels\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirming all the tokens contain a label and the attention mask also matches the length of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 97 97\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_test[\"input_ids\"][0]),len(tokenized_test[\"labels\"][0]),len(tokenized_test[\"attention_mask\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the tokenized data to datasets format with the function `load_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = load_dataset(tokenized_train)\n",
    "dataset_dev = load_dataset(tokenized_dev)\n",
    "dataset_test = load_dataset(tokenized_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model is to be run with a smaller size of the data, reducing the size of the dataset for a mini test with the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = dataset_train.shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = dataset_dev.shuffle(seed=42).select(range(1000))\n",
    "small_test_dataset = dataset_test.shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the labels that will be predicted by the model with the `get_labels_from_map`function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = get_labels_from_map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model for semantic role labelling task with function `load_srl_model` to get the model, its name and the arguments necessary for training. \\\n",
    "The model selected is **distilbert-base-uncased**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model, model_name, args = load_srl_model(model_checkpoint, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "print(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing the arguments along with the datasets to the `trainer` function to fine-tune the model for semantic role labelling with `trainer.train()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [189/189 02:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.139707</td>\n",
       "      <td>0.025898</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.027169</td>\n",
       "      <td>0.906435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.131787</td>\n",
       "      <td>0.025898</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.027169</td>\n",
       "      <td>0.906435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.129392</td>\n",
       "      <td>0.025898</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.027169</td>\n",
       "      <td>0.906435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=189, training_loss=0.10232327980969949, metrics={'train_runtime': 125.6559, 'train_samples_per_second': 23.875, 'train_steps_per_second': 1.504, 'total_flos': 138706544862000.0, 'train_loss': 0.10232327980969949, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=dataset_train,\n",
    "        eval_dataset=dataset_dev,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=lambda p: compute_metrics(*p, label_list)\n",
    "    )\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate a model fine-tuned for semantic role labelling with `trainer.evaluate()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.12939226627349854,\n",
       " 'eval_precision': 0.025898151377746776,\n",
       " 'eval_recall': 0.02857142857142857,\n",
       " 'eval_f1': 0.027169189955632802,\n",
       " 'eval_accuracy': 0.9064352982211371,\n",
       " 'eval_runtime': 5.7309,\n",
       " 'eval_samples_per_second': 174.492,\n",
       " 'eval_steps_per_second': 10.993,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training is finished, the precision/recall/f1 for each category can be computed. \\\n",
    "The same function `compute_metrics` is applied on the result of the predict method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.02915742414479349,\n",
       " 'recall': 0.03225806451612903,\n",
       " 'f1': 0.030629474410918366,\n",
       " 'accuracy': 0.9038801484885982}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(dataset_test)\n",
    "results = compute_metrics(predictions, labels, label_list)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing the predictions together with the gold labels to a csv file with the function `write_predictions_to_csv` so that the metrics per class can be computed with the `compute_evaluation_metrics_from_csv` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ARG0       0.00      0.00      0.00         0\n",
      "        ARG1       0.00      0.00      0.00         0\n",
      "        ARG2       0.00      0.00      0.00         0\n",
      "        ARG3       0.00      0.00      0.00         0\n",
      "        ARG4       0.00      0.00      0.00         0\n",
      "    ARGM-ADJ       0.00      0.00      0.00         0\n",
      "    ARGM-ADV       0.00      0.00      0.00         0\n",
      "    ARGM-CAU       0.00      0.00      0.00         0\n",
      "    ARGM-COM       0.00      0.00      0.00         0\n",
      "    ARGM-CXN       0.00      0.00      0.00         0\n",
      "    ARGM-DIR       0.00      0.00      0.00         0\n",
      "    ARGM-DIS       0.00      0.00      0.00         0\n",
      "    ARGM-EXT       0.00      0.00      0.00         0\n",
      "    ARGM-GOL       0.00      0.00      0.00         0\n",
      "    ARGM-LOC       0.00      0.00      0.00         0\n",
      "    ARGM-LVB       0.00      0.00      0.00         0\n",
      "    ARGM-MNR       0.00      0.00      0.00         0\n",
      "    ARGM-MOD       0.00      0.00      0.00         0\n",
      "    ARGM-NEG       0.00      0.00      0.00         0\n",
      "    ARGM-PRD       0.00      0.00      0.00         0\n",
      "    ARGM-PRP       0.00      0.00      0.00         0\n",
      "    ARGM-PRR       0.00      0.00      0.00         0\n",
      "    ARGM-TMP       0.00      0.00      0.00         0\n",
      "      C-ARG1       0.00      0.00      0.00         0\n",
      "      C-ARG2       0.00      0.00      0.00         0\n",
      "  C-ARGM-CXN       0.00      0.00      0.00         0\n",
      "      R-ARG0       0.00      0.00      0.00         0\n",
      "      R-ARG1       0.00      0.00      0.00         0\n",
      "  R-ARGM-LOC       0.00      0.00      0.00         0\n",
      "  R-ARGM-MNR       0.00      0.00      0.00         0\n",
      "           _       1.00      0.90      0.95     22628\n",
      "\n",
      "    accuracy                           0.90     22628\n",
      "   macro avg       0.03      0.03      0.03     22628\n",
      "weighted avg       1.00      0.90      0.95     22628\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/arianabritez/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "results_file = \"predictions.csv\"\n",
    "write_predictions_to_csv(predictions, labels, label_list, results_file)\n",
    "classification_report = compute_evaluation_metrics_from_csv(\"predictions.csv\")\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we save fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these codes to save model:\n",
    "tokenizer.save_pretrained(\"tokenizer.save_pretrained.distillbert-base-uncased-finetuned-srl\")\n",
    "trainer.save_model(\"trainer.save_model.distillbert-base-uncased-finetuned-srl\")\n",
    "model.save_pretrained(\"model.save_pretrained.distillbert-base-uncased-finetuned-srl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Here, we copy saved model to google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r '/content/trainer.save_model.distillbert-base-uncased-finetuned-srl' '/content/drive/MyDrive/NLP_3_baseline_model/model'\n",
    "!cp -r '/content/model.save_pretrained.distillbert-base-uncased-finetuned-srl' '/content/drive/MyDrive/NLP_3_baseline_model/model'\n",
    "!cp -r '/content/tokenizer.save_pretrained.distillbert-base-uncased-finetuned-srl' '/content/drive/MyDrive/NLP_3_baseline_model/model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Contribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ariana Britez: \n",
    "- functions to map the labels to number for model input: get_label_mapping, map_labels_to_numbers, map_labels_in_dataframe \n",
    "- function to get the list of labels for model input: get_labels_from_map \n",
    "- function to compute the metrics during training, evaluation and inference: compute_metrics, compute_evaluation_metrics_from_csv \n",
    "- function to load the transformer model for fine-tuning: load_srl_model\n",
    "- function to load the dataset in format that model can handle: load_dataset\n",
    "- function to save the model predictions with gold labels for evaluation: write_predictions_to_csv\n",
    "- writing markdown from importing the model section until evaluation of the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
